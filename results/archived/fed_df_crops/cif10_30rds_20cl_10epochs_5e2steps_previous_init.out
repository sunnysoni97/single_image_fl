---------
Number of crops : 500
Strategy : feddf
Communication Rounds : 30
Seed : 42
Val Ratio : 0.05
---------
Generating crops for FedDF
Namespace(img_size=32, batch_size=32, num_imgs=500, threads=12, vflip=False, deg=30, shear=30, cropfirst=True, initcrop=0.5, scale=[500, 1], randinterp=False, debug=False, imgpath='static/single_images/ameyoko.jpg', targetpath='/scratch-local/sunnys.2659640', img_per_thread=41)
will save 500 patches in /scratch-local/sunnys.2659640/single_img_crops/crops
500 took 0.03min with 12 threads
---------
Simulating FedDF training using crops
0.0%0.0%0.1%0.1%0.1%0.1%0.1%0.2%0.2%0.2%0.2%0.2%0.2%0.3%0.3%0.3%0.3%0.3%0.4%0.4%0.4%0.4%0.4%0.5%0.5%0.5%0.5%0.5%0.6%0.6%0.6%0.6%0.6%0.7%0.7%0.7%0.7%0.7%0.7%0.8%0.8%0.8%0.8%0.8%0.9%0.9%0.9%0.9%0.9%1.0%1.0%1.0%1.0%1.0%1.1%1.1%1.1%1.1%1.1%1.2%1.2%1.2%1.2%1.2%1.2%1.3%1.3%1.3%1.3%1.3%1.4%1.4%1.4%1.4%1.4%1.5%1.5%1.5%1.5%1.5%1.6%1.6%1.6%1.6%1.6%1.7%1.7%1.7%1.7%1.7%1.7%1.8%1.8%1.8%1.8%1.8%1.9%1.9%1.9%1.9%1.9%2.0%2.0%2.0%2.0%2.0%2.1%2.1%2.1%2.1%2.1%2.2%2.2%2.2%2.2%2.2%2.2%2.3%2.3%2.3%2.3%2.3%2.4%2.4%2.4%2.4%2.4%2.5%2.5%2.5%2.5%2.5%2.6%2.6%2.6%2.6%2.6%2.7%2.7%2.7%2.7%2.7%2.7%2.8%2.8%2.8%2.8%2.8%2.9%2.9%2.9%2.9%2.9%3.0%3.0%3.0%3.0%3.0%3.1%3.1%3.1%3.1%3.1%3.2%3.2%3.2%3.2%3.2%3.2%3.3%3.3%3.3%3.3%3.3%3.4%3.4%3.4%3.4%3.4%3.5%3.5%3.5%3.5%3.5%3.6%3.6%3.6%3.6%3.6%3.7%3.7%3.7%3.7%3.7%3.7%3.8%3.8%3.8%3.8%3.8%3.9%3.9%3.9%3.9%3.9%4.0%4.0%4.0%4.0%4.0%4.1%4.1%4.1%4.1%4.1%4.2%4.2%4.2%4.2%4.2%4.2%4.3%4.3%4.3%4.3%4.3%4.4%4.4%4.4%4.4%4.4%4.5%4.5%4.5%4.5%4.5%4.6%4.6%4.6%4.6%4.6%4.7%4.7%4.7%4.7%4.7%4.7%4.8%4.8%4.8%4.8%4.8%4.9%4.9%4.9%4.9%4.9%5.0%5.0%5.0%5.0%5.0%5.1%5.1%5.1%5.1%5.1%5.2%5.2%5.2%5.2%5.2%5.2%5.3%5.3%5.3%5.3%5.3%5.4%5.4%5.4%5.4%5.4%5.5%5.5%5.5%5.5%5.5%5.6%5.6%5.6%5.6%5.6%5.7%5.7%5.7%5.7%5.7%5.7%5.8%5.8%5.8%5.8%5.8%5.9%5.9%5.9%5.9%5.9%6.0%6.0%6.0%6.0%6.0%6.1%6.1%6.1%6.1%6.1%6.2%6.2%6.2%6.2%6.2%6.2%6.3%6.3%6.3%6.3%6.3%6.4%6.4%6.4%6.4%6.4%6.5%6.5%6.5%6.5%6.5%6.6%6.6%6.6%6.6%6.6%6.6%6.7%6.7%6.7%6.7%6.7%6.8%6.8%6.8%6.8%6.8%6.9%6.9%6.9%6.9%6.9%7.0%7.0%7.0%7.0%7.0%7.1%7.1%7.1%7.1%7.1%7.1%7.2%7.2%7.2%7.2%7.2%7.3%7.3%7.3%7.3%7.3%7.4%7.4%7.4%7.4%7.4%7.5%7.5%7.5%7.5%7.5%7.6%7.6%7.6%7.6%7.6%7.6%7.7%7.7%7.7%7.7%7.7%7.8%7.8%7.8%7.8%7.8%7.9%7.9%7.9%7.9%7.9%8.0%8.0%8.0%8.0%8.0%8.1%8.1%8.1%8.1%8.1%8.1%8.2%8.2%8.2%8.2%8.2%8.3%8.3%8.3%8.3%8.3%8.4%8.4%8.4%8.4%8.4%8.5%8.5%8.5%8.5%8.5%8.6%8.6%8.6%8.6%8.6%8.6%8.7%8.7%8.7%8.7%8.7%8.8%8.8%8.8%8.8%8.8%8.9%8.9%8.9%8.9%8.9%9.0%9.0%9.0%9.0%9.0%9.1%9.1%9.1%9.1%9.1%9.1%9.2%9.2%9.2%9.2%9.2%9.3%9.3%9.3%9.3%9.3%9.4%9.4%9.4%9.4%9.4%9.5%9.5%9.5%9.5%9.5%9.6%9.6%9.6%9.6%9.6%9.6%9.7%9.7%9.7%9.7%9.7%9.8%9.8%9.8%9.8%9.8%9.9%9.9%9.9%9.9%9.9%10.0%10.0%10.0%10.0%10.0%10.1%10.1%10.1%10.1%10.1%10.1%10.2%10.2%10.2%10.2%10.2%10.3%10.3%10.3%10.3%10.3%10.4%10.4%10.4%10.4%10.4%10.5%10.5%10.5%10.5%10.5%10.6%10.6%10.6%10.6%10.6%10.6%10.7%10.7%10.7%10.7%10.7%10.8%10.8%10.8%10.8%10.8%10.9%10.9%10.9%10.9%10.9%11.0%11.0%11.0%11.0%11.0%11.1%11.1%11.1%11.1%11.1%11.1%11.2%11.2%11.2%11.2%11.2%11.3%11.3%11.3%11.3%11.3%11.4%11.4%11.4%11.4%11.4%11.5%11.5%11.5%11.5%11.5%11.6%11.6%11.6%11.6%11.6%11.6%11.7%11.7%11.7%11.7%11.7%11.8%11.8%11.8%11.8%11.8%11.9%11.9%11.9%11.9%11.9%12.0%12.0%12.0%12.0%12.0%12.1%12.1%12.1%12.1%12.1%12.1%12.2%12.2%12.2%12.2%12.2%12.3%12.3%12.3%12.3%12.3%12.4%12.4%12.4%12.4%12.4%12.5%12.5%12.5%12.5%12.5%12.5%12.6%12.6%12.6%12.6%12.6%12.7%12.7%12.7%12.7%12.7%12.8%12.8%12.8%12.8%12.8%12.9%12.9%12.9%12.9%12.9%13.0%13.0%13.0%13.0%13.0%13.0%13.1%13.1%13.1%13.1%13.1%13.2%13.2%13.2%13.2%13.2%13.3%13.3%13.3%13.3%13.3%13.4%13.4%13.4%13.4%13.4%13.5%13.5%13.5%13.5%13.5%13.5%13.6%13.6%13.6%13.6%13.6%13.7%13.7%13.7%13.7%13.7%13.8%13.8%13.8%13.8%13.8%13.9%13.9%13.9%13.9%13.9%14.0%14.0%14.0%14.0%14.0%14.0%14.1%14.1%14.1%14.1%14.1%14.2%14.2%14.2%14.2%14.2%14.3%14.3%14.3%14.3%14.3%14.4%14.4%14.4%14.4%14.4%14.5%14.5%14.5%14.5%14.5%14.5%14.6%14.6%14.6%14.6%14.6%14.7%14.7%14.7%14.7%14.7%14.8%14.8%14.8%14.8%14.8%14.9%14.9%14.9%14.9%14.9%15.0%15.0%15.0%15.0%15.0%15.0%15.1%15.1%15.1%15.1%15.1%15.2%15.2%15.2%15.2%15.2%15.3%15.3%15.3%15.3%15.3%15.4%15.4%15.4%15.4%15.4%15.5%15.5%15.5%15.5%15.5%15.5%15.6%15.6%15.6%15.6%15.6%15.7%15.7%15.7%15.7%15.7%15.8%15.8%15.8%15.8%15.8%15.9%15.9%15.9%15.9%15.9%16.0%16.0%16.0%16.0%16.0%16.0%16.1%16.1%16.1%16.1%16.1%16.2%16.2%16.2%16.2%16.2%16.3%16.3%16.3%16.3%16.3%16.4%16.4%16.4%16.4%16.4%16.5%16.5%16.5%16.5%16.5%16.5%16.6%16.6%16.6%16.6%16.6%16.7%16.7%16.7%16.7%16.7%16.8%16.8%16.8%16.8%16.8%16.9%16.9%16.9%16.9%16.9%17.0%17.0%17.0%17.0%17.0%17.0%17.1%17.1%17.1%17.1%17.1%17.2%17.2%17.2%17.2%17.2%17.3%17.3%17.3%17.3%17.3%17.4%17.4%17.4%17.4%17.4%17.5%17.5%17.5%17.5%17.5%17.5%17.6%17.6%17.6%17.6%17.6%17.7%17.7%17.7%17.7%17.7%17.8%17.8%17.8%17.8%17.8%17.9%17.9%17.9%17.9%17.9%18.0%18.0%18.0%18.0%18.0%18.0%18.1%18.1%18.1%18.1%18.1%18.2%18.2%18.2%18.2%18.2%18.3%18.3%18.3%18.3%18.3%18.4%18.4%18.4%18.4%18.4%18.5%18.5%18.5%18.5%18.5%18.5%18.6%18.6%18.6%18.6%18.6%18.7%18.7%18.7%18.7%18.7%18.8%18.8%18.8%18.8%18.8%18.9%18.9%18.9%18.9%18.9%18.9%19.0%19.0%19.0%19.0%19.0%19.1%19.1%19.1%19.1%19.1%19.2%19.2%19.2%19.2%19.2%19.3%19.3%19.3%19.3%19.3%19.4%19.4%19.4%19.4%19.4%19.4%19.5%19.5%19.5%19.5%19.5%19.6%19.6%19.6%19.6%19.6%19.7%19.7%19.7%19.7%19.7%19.8%19.8%19.8%19.8%19.8%19.9%19.9%19.9%19.9%19.9%19.9%20.0%20.0%20.0%20.0%20.0%20.1%20.1%20.1%20.1%20.1%20.2%20.2%20.2%20.2%20.2%20.3%20.3%20.3%20.3%20.3%20.4%20.4%20.4%20.4%20.4%20.4%20.5%20.5%20.5%20.5%20.5%20.6%20.6%20.6%20.6%20.6%20.7%20.7%20.7%20.7%20.7%20.8%20.8%20.8%20.8%20.8%20.9%20.9%20.9%20.9%20.9%20.9%21.0%21.0%21.0%21.0%21.0%21.1%21.1%21.1%21.1%21.1%21.2%21.2%21.2%21.2%21.2%21.3%21.3%21.3%21.3%21.3%21.4%21.4%21.4%21.4%21.4%21.4%21.5%21.5%21.5%21.5%21.5%21.6%21.6%21.6%21.6%21.6%21.7%21.7%21.7%21.7%21.7%21.8%21.8%21.8%21.8%21.8%21.9%21.9%21.9%21.9%21.9%21.9%22.0%22.0%22.0%22.0%22.0%22.1%22.1%22.1%22.1%22.1%22.2%22.2%22.2%22.2%22.2%22.3%22.3%22.3%22.3%22.3%22.4%22.4%22.4%22.4%22.4%22.4%22.5%22.5%22.5%22.5%22.5%22.6%22.6%22.6%22.6%22.6%22.7%22.7%22.7%22.7%22.7%22.8%22.8%22.8%22.8%22.8%22.9%22.9%22.9%22.9%22.9%22.9%23.0%23.0%23.0%23.0%23.0%23.1%23.1%23.1%23.1%23.1%23.2%23.2%23.2%23.2%23.2%23.3%23.3%23.3%23.3%23.3%23.4%23.4%23.4%23.4%23.4%23.4%23.5%23.5%23.5%23.5%23.5%23.6%23.6%23.6%23.6%23.6%23.7%23.7%23.7%23.7%23.7%23.8%23.8%23.8%23.8%23.8%23.9%23.9%23.9%23.9%23.9%23.9%24.0%24.0%24.0%24.0%24.0%24.1%24.1%24.1%24.1%24.1%24.2%24.2%24.2%24.2%24.2%24.3%24.3%24.3%24.3%24.3%24.4%24.4%24.4%24.4%24.4%24.4%24.5%24.5%24.5%24.5%24.5%24.6%24.6%24.6%24.6%24.6%24.7%24.7%24.7%24.7%24.7%24.8%24.8%24.8%24.8%24.8%24.9%24.9%24.9%24.9%24.9%24.9%25.0%25.0%25.0%25.0%25.0%25.1%25.1%25.1%25.1%25.1%25.2%25.2%25.2%25.2%25.2%25.3%25.3%25.3%25.3%25.3%25.3%25.4%25.4%25.4%25.4%25.4%25.5%25.5%25.5%25.5%25.5%25.6%25.6%25.6%25.6%25.6%25.7%25.7%25.7%25.7%25.7%25.8%25.8%25.8%25.8%25.8%25.8%25.9%25.9%25.9%25.9%25.9%26.0%26.0%26.0%26.0%26.0%26.1%26.1%26.1%26.1%26.1%26.2%26.2%26.2%26.2%26.2%26.3%26.3%26.3%26.3%26.3%26.3%26.4%26.4%26.4%26.4%26.4%26.5%26.5%26.5%26.5%26.5%26.6%26.6%26.6%26.6%26.6%26.7%26.7%26.7%26.7%26.7%26.8%26.8%26.8%26.8%26.8%26.8%26.9%26.9%26.9%26.9%26.9%27.0%27.0%27.0%27.0%27.0%27.1%27.1%27.1%27.1%27.1%27.2%27.2%27.2%27.2%27.2%27.3%27.3%27.3%27.3%27.3%27.3%27.4%27.4%27.4%27.4%27.4%27.5%27.5%27.5%27.5%27.5%27.6%27.6%27.6%27.6%27.6%27.7%27.7%27.7%27.7%27.7%27.8%27.8%27.8%27.8%27.8%27.8%27.9%27.9%27.9%27.9%27.9%28.0%28.0%28.0%28.0%28.0%28.1%28.1%28.1%28.1%28.1%28.2%28.2%28.2%28.2%28.2%28.3%28.3%28.3%28.3%28.3%28.3%28.4%28.4%28.4%28.4%28.4%28.5%28.5%28.5%28.5%28.5%28.6%28.6%28.6%28.6%28.6%28.7%28.7%28.7%28.7%28.7%28.8%28.8%28.8%28.8%28.8%28.8%28.9%28.9%28.9%28.9%28.9%29.0%29.0%29.0%29.0%29.0%29.1%29.1%29.1%29.1%29.1%29.2%29.2%29.2%29.2%29.2%29.3%29.3%29.3%29.3%29.3%29.3%29.4%29.4%29.4%29.4%29.4%29.5%29.5%29.5%29.5%29.5%29.6%29.6%29.6%29.6%29.6%29.7%29.7%29.7%29.7%29.7%29.8%29.8%29.8%29.8%29.8%29.8%29.9%29.9%29.9%29.9%29.9%30.0%30.0%30.0%30.0%30.0%30.1%30.1%30.1%30.1%30.1%30.2%30.2%30.2%30.2%30.2%30.3%30.3%30.3%30.3%30.3%30.3%30.4%30.4%30.4%30.4%30.4%30.5%30.5%30.5%30.5%30.5%30.6%30.6%30.6%30.6%30.6%30.7%30.7%30.7%30.7%30.7%30.8%30.8%30.8%30.8%30.8%30.8%30.9%30.9%30.9%30.9%30.9%31.0%31.0%31.0%31.0%31.0%31.1%31.1%31.1%31.1%31.1%31.2%31.2%31.2%31.2%31.2%31.3%31.3%31.3%31.3%31.3%31.3%31.4%31.4%31.4%31.4%31.4%31.5%31.5%31.5%31.5%31.5%31.6%31.6%31.6%31.6%31.6%31.7%31.7%31.7%31.7%31.7%31.7%31.8%31.8%31.8%31.8%31.8%31.9%31.9%31.9%31.9%31.9%32.0%32.0%32.0%32.0%32.0%32.1%32.1%32.1%32.1%32.1%32.2%32.2%32.2%32.2%32.2%32.2%32.3%32.3%32.3%32.3%32.3%32.4%32.4%32.4%32.4%32.4%32.5%32.5%32.5%32.5%32.5%32.6%32.6%32.6%32.6%32.6%32.7%32.7%32.7%32.7%32.7%32.7%32.8%32.8%32.8%32.8%32.8%32.9%32.9%32.9%32.9%32.9%33.0%33.0%33.0%33.0%33.0%33.1%33.1%33.1%33.1%33.1%33.2%33.2%33.2%33.2%33.2%33.2%33.3%33.3%33.3%33.3%33.3%33.4%33.4%33.4%33.4%33.4%33.5%33.5%33.5%33.5%33.5%33.6%33.6%33.6%33.6%33.6%33.7%33.7%33.7%33.7%33.7%33.7%33.8%33.8%33.8%33.8%33.8%33.9%33.9%33.9%33.9%33.9%34.0%34.0%34.0%34.0%34.0%34.1%34.1%34.1%34.1%34.1%34.2%34.2%34.2%34.2%34.2%34.2%34.3%34.3%34.3%34.3%34.3%34.4%34.4%34.4%34.4%34.4%34.5%34.5%34.5%34.5%34.5%34.6%34.6%34.6%34.6%34.6%34.7%34.7%34.7%34.7%34.7%34.7%34.8%34.8%34.8%34.8%34.8%34.9%34.9%34.9%34.9%34.9%35.0%35.0%35.0%35.0%35.0%35.1%35.1%35.1%35.1%35.1%35.2%35.2%35.2%35.2%35.2%35.2%35.3%35.3%35.3%35.3%35.3%35.4%35.4%35.4%35.4%35.4%35.5%35.5%35.5%35.5%35.5%35.6%35.6%35.6%35.6%35.6%35.7%35.7%35.7%35.7%35.7%35.7%35.8%35.8%35.8%35.8%35.8%35.9%35.9%35.9%35.9%35.9%36.0%36.0%36.0%36.0%36.0%36.1%36.1%36.1%36.1%36.1%36.2%36.2%36.2%36.2%36.2%36.2%36.3%36.3%36.3%36.3%36.3%36.4%36.4%36.4%36.4%36.4%36.5%36.5%36.5%36.5%36.5%36.6%36.6%36.6%36.6%36.6%36.7%36.7%36.7%36.7%36.7%36.7%36.8%36.8%36.8%36.8%36.8%36.9%36.9%36.9%36.9%36.9%37.0%37.0%37.0%37.0%37.0%37.1%37.1%37.1%37.1%37.1%37.2%37.2%37.2%37.2%37.2%37.2%37.3%37.3%37.3%37.3%37.3%37.4%37.4%37.4%37.4%37.4%37.5%37.5%37.5%37.5%37.5%37.6%37.6%37.6%37.6%37.6%37.6%37.7%37.7%37.7%37.7%37.7%37.8%37.8%37.8%37.8%37.8%37.9%37.9%37.9%37.9%37.9%38.0%38.0%38.0%38.0%38.0%38.1%38.1%38.1%38.1%38.1%38.1%38.2%38.2%38.2%38.2%38.2%38.3%38.3%38.3%38.3%38.3%38.4%38.4%38.4%38.4%38.4%38.5%38.5%38.5%38.5%38.5%38.6%38.6%38.6%38.6%38.6%38.6%38.7%38.7%38.7%38.7%38.7%38.8%38.8%38.8%38.8%38.8%38.9%38.9%38.9%38.9%38.9%39.0%39.0%39.0%39.0%39.0%39.1%39.1%39.1%39.1%39.1%39.1%39.2%39.2%39.2%39.2%39.2%39.3%39.3%39.3%39.3%39.3%39.4%39.4%39.4%39.4%39.4%39.5%39.5%39.5%39.5%39.5%39.6%39.6%39.6%39.6%39.6%39.6%39.7%39.7%39.7%39.7%39.7%39.8%39.8%39.8%39.8%39.8%39.9%39.9%39.9%39.9%39.9%40.0%40.0%40.0%40.0%40.0%40.1%40.1%40.1%40.1%40.1%40.1%40.2%40.2%40.2%40.2%40.2%40.3%40.3%40.3%40.3%40.3%40.4%40.4%40.4%40.4%40.4%40.5%40.5%40.5%40.5%40.5%40.6%40.6%40.6%40.6%40.6%40.6%40.7%40.7%40.7%40.7%40.7%40.8%40.8%40.8%40.8%40.8%40.9%40.9%40.9%40.9%40.9%41.0%41.0%41.0%41.0%41.0%41.1%41.1%41.1%41.1%41.1%41.1%41.2%41.2%41.2%41.2%41.2%41.3%41.3%41.3%41.3%41.3%41.4%41.4%41.4%41.4%41.4%41.5%41.5%41.5%41.5%41.5%41.6%41.6%41.6%41.6%41.6%41.6%41.7%41.7%41.7%41.7%41.7%41.8%41.8%41.8%41.8%41.8%41.9%41.9%41.9%41.9%41.9%42.0%42.0%42.0%42.0%42.0%42.1%42.1%42.1%42.1%42.1%42.1%42.2%42.2%42.2%42.2%42.2%42.3%42.3%42.3%42.3%42.3%42.4%42.4%42.4%42.4%42.4%42.5%42.5%42.5%42.5%42.5%42.6%42.6%42.6%42.6%42.6%42.6%42.7%42.7%42.7%42.7%42.7%42.8%42.8%42.8%42.8%42.8%42.9%42.9%42.9%42.9%42.9%43.0%43.0%43.0%43.0%43.0%43.1%43.1%43.1%43.1%43.1%43.1%43.2%43.2%43.2%43.2%43.2%43.3%43.3%43.3%43.3%43.3%43.4%43.4%43.4%43.4%43.4%43.5%43.5%43.5%43.5%43.5%43.6%43.6%43.6%43.6%43.6%43.6%43.7%43.7%43.7%43.7%43.7%43.8%43.8%43.8%43.8%43.8%43.9%43.9%43.9%43.9%43.9%44.0%44.0%44.0%44.0%44.0%44.0%44.1%44.1%44.1%44.1%44.1%44.2%44.2%44.2%44.2%44.2%44.3%44.3%44.3%44.3%44.3%44.4%44.4%44.4%44.4%44.4%44.5%44.5%44.5%44.5%44.5%44.5%44.6%44.6%44.6%44.6%44.6%44.7%44.7%44.7%44.7%44.7%44.8%44.8%44.8%44.8%44.8%44.9%44.9%44.9%44.9%44.9%45.0%45.0%45.0%45.0%45.0%45.0%45.1%45.1%45.1%45.1%45.1%45.2%45.2%45.2%45.2%45.2%45.3%45.3%45.3%45.3%45.3%45.4%45.4%45.4%45.4%45.4%45.5%45.5%45.5%45.5%45.5%45.5%45.6%45.6%45.6%45.6%45.6%45.7%45.7%45.7%45.7%45.7%45.8%45.8%45.8%45.8%45.8%45.9%45.9%45.9%45.9%45.9%46.0%46.0%46.0%46.0%46.0%46.0%46.1%46.1%46.1%46.1%46.1%46.2%46.2%46.2%46.2%46.2%46.3%46.3%46.3%46.3%46.3%46.4%46.4%46.4%46.4%46.4%46.5%46.5%46.5%46.5%46.5%46.5%46.6%46.6%46.6%46.6%46.6%46.7%46.7%46.7%46.7%46.7%46.8%46.8%46.8%46.8%46.8%46.9%46.9%46.9%46.9%46.9%47.0%47.0%47.0%47.0%47.0%47.0%47.1%47.1%47.1%47.1%47.1%47.2%47.2%47.2%47.2%47.2%47.3%47.3%47.3%47.3%47.3%47.4%47.4%47.4%47.4%47.4%47.5%47.5%47.5%47.5%47.5%47.5%47.6%47.6%47.6%47.6%47.6%47.7%47.7%47.7%47.7%47.7%47.8%47.8%47.8%47.8%47.8%47.9%47.9%47.9%47.9%47.9%48.0%48.0%48.0%48.0%48.0%48.0%48.1%48.1%48.1%48.1%48.1%48.2%48.2%48.2%48.2%48.2%48.3%48.3%48.3%48.3%48.3%48.4%48.4%48.4%48.4%48.4%48.5%48.5%48.5%48.5%48.5%48.5%48.6%48.6%48.6%48.6%48.6%48.7%48.7%48.7%48.7%48.7%48.8%48.8%48.8%48.8%48.8%48.9%48.9%48.9%48.9%48.9%49.0%49.0%49.0%49.0%49.0%49.0%49.1%49.1%49.1%49.1%49.1%49.2%49.2%49.2%49.2%49.2%49.3%49.3%49.3%49.3%49.3%49.4%49.4%49.4%49.4%49.4%49.5%49.5%49.5%49.5%49.5%49.5%49.6%49.6%49.6%49.6%49.6%49.7%49.7%49.7%49.7%49.7%49.8%49.8%49.8%49.8%49.8%49.9%49.9%49.9%49.9%49.9%50.0%50.0%50.0%50.0%50.0%50.0%50.1%50.1%50.1%50.1%50.1%50.2%50.2%50.2%50.2%50.2%50.3%50.3%50.3%50.3%50.3%50.4%50.4%50.4%50.4%50.4%50.4%50.5%50.5%50.5%50.5%50.5%50.6%50.6%50.6%50.6%50.6%50.7%50.7%50.7%50.7%50.7%50.8%50.8%50.8%50.8%50.8%50.9%50.9%50.9%50.9%50.9%50.9%51.0%51.0%51.0%51.0%51.0%51.1%51.1%51.1%51.1%51.1%51.2%51.2%51.2%51.2%51.2%51.3%51.3%51.3%51.3%51.3%51.4%51.4%51.4%51.4%51.4%51.4%51.5%51.5%51.5%51.5%51.5%51.6%51.6%51.6%51.6%51.6%51.7%51.7%51.7%51.7%51.7%51.8%51.8%51.8%51.8%51.8%51.9%51.9%51.9%51.9%51.9%51.9%52.0%52.0%52.0%52.0%52.0%52.1%52.1%52.1%52.1%52.1%52.2%52.2%52.2%52.2%52.2%52.3%52.3%52.3%52.3%52.3%52.4%52.4%52.4%52.4%52.4%52.4%52.5%52.5%52.5%52.5%52.5%52.6%52.6%52.6%52.6%52.6%52.7%52.7%52.7%52.7%52.7%52.8%52.8%52.8%52.8%52.8%52.9%52.9%52.9%52.9%52.9%52.9%53.0%53.0%53.0%53.0%53.0%53.1%53.1%53.1%53.1%53.1%53.2%53.2%53.2%53.2%53.2%53.3%53.3%53.3%53.3%53.3%53.4%53.4%53.4%53.4%53.4%53.4%53.5%53.5%53.5%53.5%53.5%53.6%53.6%53.6%53.6%53.6%53.7%53.7%53.7%53.7%53.7%53.8%53.8%53.8%53.8%53.8%53.9%53.9%53.9%53.9%53.9%53.9%54.0%54.0%54.0%54.0%54.0%54.1%54.1%54.1%54.1%54.1%54.2%54.2%54.2%54.2%54.2%54.3%54.3%54.3%54.3%54.3%54.4%54.4%54.4%54.4%54.4%54.4%54.5%54.5%54.5%54.5%54.5%54.6%54.6%54.6%54.6%54.6%54.7%54.7%54.7%54.7%54.7%54.8%54.8%54.8%54.8%54.8%54.9%54.9%54.9%54.9%54.9%54.9%55.0%55.0%55.0%55.0%55.0%55.1%55.1%55.1%55.1%55.1%55.2%55.2%55.2%55.2%55.2%55.3%55.3%55.3%55.3%55.3%55.4%55.4%55.4%55.4%55.4%55.4%55.5%55.5%55.5%55.5%55.5%55.6%55.6%55.6%55.6%55.6%55.7%55.7%55.7%55.7%55.7%55.8%55.8%55.8%55.8%55.8%55.9%55.9%55.9%55.9%55.9%55.9%56.0%56.0%56.0%56.0%56.0%56.1%56.1%56.1%56.1%56.1%56.2%56.2%56.2%56.2%56.2%56.3%56.3%56.3%56.3%56.3%56.4%56.4%56.4%56.4%56.4%56.4%56.5%56.5%56.5%56.5%56.5%56.6%56.6%56.6%56.6%56.6%56.7%56.7%56.7%56.7%56.7%56.8%56.8%56.8%56.8%56.8%56.8%56.9%56.9%56.9%56.9%56.9%57.0%57.0%57.0%57.0%57.0%57.1%57.1%57.1%57.1%57.1%57.2%57.2%57.2%57.2%57.2%57.3%57.3%57.3%57.3%57.3%57.3%57.4%57.4%57.4%57.4%57.4%57.5%57.5%57.5%57.5%57.5%57.6%57.6%57.6%57.6%57.6%57.7%57.7%57.7%57.7%57.7%57.8%57.8%57.8%57.8%57.8%57.8%57.9%57.9%57.9%57.9%57.9%58.0%58.0%58.0%58.0%58.0%58.1%58.1%58.1%58.1%58.1%58.2%58.2%58.2%58.2%58.2%58.3%58.3%58.3%58.3%58.3%58.3%58.4%58.4%58.4%58.4%58.4%58.5%58.5%58.5%58.5%58.5%58.6%58.6%58.6%58.6%58.6%58.7%58.7%58.7%58.7%58.7%58.8%58.8%58.8%58.8%58.8%58.8%58.9%58.9%58.9%58.9%58.9%59.0%59.0%59.0%59.0%59.0%59.1%59.1%59.1%59.1%59.1%59.2%59.2%59.2%59.2%59.2%59.3%59.3%59.3%59.3%59.3%59.3%59.4%59.4%59.4%59.4%59.4%59.5%59.5%59.5%59.5%59.5%59.6%59.6%59.6%59.6%59.6%59.7%59.7%59.7%59.7%59.7%59.8%59.8%59.8%59.8%59.8%59.8%59.9%59.9%59.9%59.9%59.9%60.0%60.0%60.0%60.0%60.0%60.1%60.1%60.1%60.1%60.1%60.2%60.2%60.2%60.2%60.2%60.3%60.3%60.3%60.3%60.3%60.3%60.4%60.4%60.4%60.4%60.4%60.5%60.5%60.5%60.5%60.5%60.6%60.6%60.6%60.6%60.6%60.7%60.7%60.7%60.7%60.7%60.8%60.8%60.8%60.8%60.8%60.8%60.9%60.9%60.9%60.9%60.9%61.0%61.0%61.0%61.0%61.0%61.1%61.1%61.1%61.1%61.1%61.2%61.2%61.2%61.2%61.2%61.3%61.3%61.3%61.3%61.3%61.3%61.4%61.4%61.4%61.4%61.4%61.5%61.5%61.5%61.5%61.5%61.6%61.6%61.6%61.6%61.6%61.7%61.7%61.7%61.7%61.7%61.8%61.8%61.8%61.8%61.8%61.8%61.9%61.9%61.9%61.9%61.9%62.0%62.0%62.0%62.0%62.0%62.1%62.1%62.1%62.1%62.1%62.2%62.2%62.2%62.2%62.2%62.3%62.3%62.3%62.3%62.3%62.3%62.4%62.4%62.4%62.4%62.4%62.5%62.5%62.5%62.5%62.5%62.6%62.6%62.6%62.6%62.6%62.7%62.7%62.7%62.7%62.7%62.7%62.8%62.8%62.8%62.8%62.8%62.9%62.9%62.9%62.9%62.9%63.0%63.0%63.0%63.0%63.0%63.1%63.1%63.1%63.1%63.1%63.2%63.2%63.2%63.2%63.2%63.2%63.3%63.3%63.3%63.3%63.3%63.4%63.4%63.4%63.4%63.4%63.5%63.5%63.5%63.5%63.5%63.6%63.6%63.6%63.6%63.6%63.7%63.7%63.7%63.7%63.7%63.7%63.8%63.8%63.8%63.8%63.8%63.9%63.9%63.9%63.9%63.9%64.0%64.0%64.0%64.0%64.0%64.1%64.1%64.1%64.1%64.1%64.2%64.2%64.2%64.2%64.2%64.2%64.3%64.3%64.3%64.3%64.3%64.4%64.4%64.4%64.4%64.4%64.5%64.5%64.5%64.5%64.5%64.6%64.6%64.6%64.6%64.6%64.7%64.7%64.7%64.7%64.7%64.7%64.8%64.8%64.8%64.8%64.8%64.9%64.9%64.9%64.9%64.9%65.0%65.0%65.0%65.0%65.0%65.1%65.1%65.1%65.1%65.1%65.2%65.2%65.2%65.2%65.2%65.2%65.3%65.3%65.3%65.3%65.3%65.4%65.4%65.4%65.4%65.4%65.5%65.5%65.5%65.5%65.5%65.6%65.6%65.6%65.6%65.6%65.7%65.7%65.7%65.7%65.7%65.7%65.8%65.8%65.8%65.8%65.8%65.9%65.9%65.9%65.9%65.9%66.0%66.0%66.0%66.0%66.0%66.1%66.1%66.1%66.1%66.1%66.2%66.2%66.2%66.2%66.2%66.2%66.3%66.3%66.3%66.3%66.3%66.4%66.4%66.4%66.4%66.4%66.5%66.5%66.5%66.5%66.5%66.6%66.6%66.6%66.6%66.6%66.7%66.7%66.7%66.7%66.7%66.7%66.8%66.8%66.8%66.8%66.8%66.9%66.9%66.9%66.9%66.9%67.0%67.0%67.0%67.0%67.0%67.1%67.1%67.1%67.1%67.1%67.2%67.2%67.2%67.2%67.2%67.2%67.3%67.3%67.3%67.3%67.3%67.4%67.4%67.4%67.4%67.4%67.5%67.5%67.5%67.5%67.5%67.6%67.6%67.6%67.6%67.6%67.7%67.7%67.7%67.7%67.7%67.7%67.8%67.8%67.8%67.8%67.8%67.9%67.9%67.9%67.9%67.9%68.0%68.0%68.0%68.0%68.0%68.1%68.1%68.1%68.1%68.1%68.2%68.2%68.2%68.2%68.2%68.2%68.3%68.3%68.3%68.3%68.3%68.4%68.4%68.4%68.4%68.4%68.5%68.5%68.5%68.5%68.5%68.6%68.6%68.6%68.6%68.6%68.7%68.7%68.7%68.7%68.7%68.7%68.8%68.8%68.8%68.8%68.8%68.9%68.9%68.9%68.9%68.9%69.0%69.0%69.0%69.0%69.0%69.1%69.1%69.1%69.1%69.1%69.1%69.2%69.2%69.2%69.2%69.2%69.3%69.3%69.3%69.3%69.3%69.4%69.4%69.4%69.4%69.4%69.5%69.5%69.5%69.5%69.5%69.6%69.6%69.6%69.6%69.6%69.6%69.7%69.7%69.7%69.7%69.7%69.8%69.8%69.8%69.8%69.8%69.9%69.9%69.9%69.9%69.9%70.0%70.0%70.0%70.0%70.0%70.1%70.1%70.1%70.1%70.1%70.1%70.2%70.2%70.2%70.2%70.2%70.3%70.3%70.3%70.3%70.3%70.4%70.4%70.4%70.4%70.4%70.5%70.5%70.5%70.5%70.5%70.6%70.6%70.6%70.6%70.6%70.6%70.7%70.7%70.7%70.7%70.7%70.8%70.8%70.8%70.8%70.8%70.9%70.9%70.9%70.9%70.9%71.0%71.0%71.0%71.0%71.0%71.1%71.1%71.1%71.1%71.1%71.1%71.2%71.2%71.2%71.2%71.2%71.3%71.3%71.3%71.3%71.3%71.4%71.4%71.4%71.4%71.4%71.5%71.5%71.5%71.5%71.5%71.6%71.6%71.6%71.6%71.6%71.6%71.7%71.7%71.7%71.7%71.7%71.8%71.8%71.8%71.8%71.8%71.9%71.9%71.9%71.9%71.9%72.0%72.0%72.0%72.0%72.0%72.1%72.1%72.1%72.1%72.1%72.1%72.2%72.2%72.2%72.2%72.2%72.3%72.3%72.3%72.3%72.3%72.4%72.4%72.4%72.4%72.4%72.5%72.5%72.5%72.5%72.5%72.6%72.6%72.6%72.6%72.6%72.6%72.7%72.7%72.7%72.7%72.7%72.8%72.8%72.8%72.8%72.8%72.9%72.9%72.9%72.9%72.9%73.0%73.0%73.0%73.0%73.0%73.1%73.1%73.1%73.1%73.1%73.1%73.2%73.2%73.2%73.2%73.2%73.3%73.3%73.3%73.3%73.3%73.4%73.4%73.4%73.4%73.4%73.5%73.5%73.5%73.5%73.5%73.6%73.6%73.6%73.6%73.6%73.6%73.7%73.7%73.7%73.7%73.7%73.8%73.8%73.8%73.8%73.8%73.9%73.9%73.9%73.9%73.9%74.0%74.0%74.0%74.0%74.0%74.1%74.1%74.1%74.1%74.1%74.1%74.2%74.2%74.2%74.2%74.2%74.3%74.3%74.3%74.3%74.3%74.4%74.4%74.4%74.4%74.4%74.5%74.5%74.5%74.5%74.5%74.6%74.6%74.6%74.6%74.6%74.6%74.7%74.7%74.7%74.7%74.7%74.8%74.8%74.8%74.8%74.8%74.9%74.9%74.9%74.9%74.9%75.0%75.0%75.0%75.0%75.0%75.1%75.1%75.1%75.1%75.1%75.1%75.2%75.2%75.2%75.2%75.2%75.3%75.3%75.3%75.3%75.3%75.4%75.4%75.4%75.4%75.4%75.5%75.5%75.5%75.5%75.5%75.5%75.6%75.6%75.6%75.6%75.6%75.7%75.7%75.7%75.7%75.7%75.8%75.8%75.8%75.8%75.8%75.9%75.9%75.9%75.9%75.9%76.0%76.0%76.0%76.0%76.0%76.0%76.1%76.1%76.1%76.1%76.1%76.2%76.2%76.2%76.2%76.2%76.3%76.3%76.3%76.3%76.3%76.4%76.4%76.4%76.4%76.4%76.5%76.5%76.5%76.5%76.5%76.5%76.6%76.6%76.6%76.6%76.6%76.7%76.7%76.7%76.7%76.7%76.8%76.8%76.8%76.8%76.8%76.9%76.9%76.9%76.9%76.9%77.0%77.0%77.0%77.0%77.0%77.0%77.1%77.1%77.1%77.1%77.1%77.2%77.2%77.2%77.2%77.2%77.3%77.3%77.3%77.3%77.3%77.4%77.4%77.4%77.4%77.4%77.5%77.5%77.5%77.5%77.5%77.5%77.6%77.6%77.6%77.6%77.6%77.7%77.7%77.7%77.7%77.7%77.8%77.8%77.8%77.8%77.8%77.9%77.9%77.9%77.9%77.9%78.0%78.0%78.0%78.0%78.0%78.0%78.1%78.1%78.1%78.1%78.1%78.2%78.2%78.2%78.2%78.2%78.3%78.3%78.3%78.3%78.3%78.4%78.4%78.4%78.4%78.4%78.5%78.5%78.5%78.5%78.5%78.5%78.6%78.6%78.6%78.6%78.6%78.7%78.7%78.7%78.7%78.7%78.8%78.8%78.8%78.8%78.8%78.9%78.9%78.9%78.9%78.9%79.0%79.0%79.0%79.0%79.0%79.0%79.1%79.1%79.1%79.1%79.1%79.2%79.2%79.2%79.2%79.2%79.3%79.3%79.3%79.3%79.3%79.4%79.4%79.4%79.4%79.4%79.5%79.5%79.5%79.5%79.5%79.5%79.6%79.6%79.6%79.6%79.6%79.7%79.7%79.7%79.7%79.7%79.8%79.8%79.8%79.8%79.8%79.9%79.9%79.9%79.9%79.9%80.0%80.0%80.0%80.0%80.0%80.0%80.1%80.1%80.1%80.1%80.1%80.2%80.2%80.2%80.2%80.2%80.3%80.3%80.3%80.3%80.3%80.4%80.4%80.4%80.4%80.4%80.5%80.5%80.5%80.5%80.5%80.5%80.6%80.6%80.6%80.6%80.6%80.7%80.7%80.7%80.7%80.7%80.8%80.8%80.8%80.8%80.8%80.9%80.9%80.9%80.9%80.9%81.0%81.0%81.0%81.0%81.0%81.0%81.1%81.1%81.1%81.1%81.1%81.2%81.2%81.2%81.2%81.2%81.3%81.3%81.3%81.3%81.3%81.4%81.4%81.4%81.4%81.4%81.5%81.5%81.5%81.5%81.5%81.5%81.6%81.6%81.6%81.6%81.6%81.7%81.7%81.7%81.7%81.7%81.8%81.8%81.8%81.8%81.8%81.9%81.9%81.9%81.9%81.9%81.9%82.0%82.0%82.0%82.0%82.0%82.1%82.1%82.1%82.1%82.1%82.2%82.2%82.2%82.2%82.2%82.3%82.3%82.3%82.3%82.3%82.4%82.4%82.4%82.4%82.4%82.4%82.5%82.5%82.5%82.5%82.5%82.6%82.6%82.6%82.6%82.6%82.7%82.7%82.7%82.7%82.7%82.8%82.8%82.8%82.8%82.8%82.9%82.9%82.9%82.9%82.9%82.9%83.0%83.0%83.0%83.0%83.0%83.1%83.1%83.1%83.1%83.1%83.2%83.2%83.2%83.2%83.2%83.3%83.3%83.3%83.3%83.3%83.4%83.4%83.4%83.4%83.4%83.4%83.5%83.5%83.5%83.5%83.5%83.6%83.6%83.6%83.6%83.6%83.7%83.7%83.7%83.7%83.7%83.8%83.8%83.8%83.8%83.8%83.9%83.9%83.9%83.9%83.9%83.9%84.0%84.0%84.0%84.0%84.0%84.1%84.1%84.1%84.1%84.1%84.2%84.2%84.2%84.2%84.2%84.3%84.3%84.3%84.3%84.3%84.4%84.4%84.4%84.4%84.4%84.4%84.5%84.5%84.5%84.5%84.5%84.6%84.6%84.6%84.6%84.6%84.7%84.7%84.7%84.7%84.7%84.8%84.8%84.8%84.8%84.8%84.9%84.9%84.9%84.9%84.9%84.9%85.0%85.0%85.0%85.0%85.0%85.1%85.1%85.1%85.1%85.1%85.2%85.2%85.2%85.2%85.2%85.3%85.3%85.3%85.3%85.3%85.4%85.4%85.4%85.4%85.4%85.4%85.5%85.5%85.5%85.5%85.5%85.6%85.6%85.6%85.6%85.6%85.7%85.7%85.7%85.7%85.7%85.8%85.8%85.8%85.8%85.8%85.9%85.9%85.9%85.9%85.9%85.9%86.0%86.0%86.0%86.0%86.0%86.1%86.1%86.1%86.1%86.1%86.2%86.2%86.2%86.2%86.2%86.3%86.3%86.3%86.3%86.3%86.4%86.4%86.4%86.4%86.4%86.4%86.5%86.5%86.5%86.5%86.5%86.6%86.6%86.6%86.6%86.6%86.7%86.7%86.7%86.7%86.7%86.8%86.8%86.8%86.8%86.8%86.9%86.9%86.9%86.9%86.9%86.9%87.0%87.0%87.0%87.0%87.0%87.1%87.1%87.1%87.1%87.1%87.2%87.2%87.2%87.2%87.2%87.3%87.3%87.3%87.3%87.3%87.4%87.4%87.4%87.4%87.4%87.4%87.5%87.5%87.5%87.5%87.5%87.6%87.6%87.6%87.6%87.6%87.7%87.7%87.7%87.7%87.7%87.8%87.8%87.8%87.8%87.8%87.8%87.9%87.9%87.9%87.9%87.9%88.0%88.0%88.0%88.0%88.0%88.1%88.1%88.1%88.1%88.1%88.2%88.2%88.2%88.2%88.2%88.3%88.3%88.3%88.3%88.3%88.3%88.4%88.4%88.4%88.4%88.4%88.5%88.5%88.5%88.5%88.5%88.6%88.6%88.6%88.6%88.6%88.7%88.7%88.7%88.7%88.7%88.8%88.8%88.8%88.8%88.8%88.8%88.9%88.9%88.9%88.9%88.9%89.0%89.0%89.0%89.0%89.0%89.1%89.1%89.1%89.1%89.1%89.2%89.2%89.2%89.2%89.2%89.3%89.3%89.3%89.3%89.3%89.3%89.4%89.4%89.4%89.4%89.4%89.5%89.5%89.5%89.5%89.5%89.6%89.6%89.6%89.6%89.6%89.7%89.7%89.7%89.7%89.7%89.8%89.8%89.8%89.8%89.8%89.8%89.9%89.9%89.9%89.9%89.9%90.0%90.0%90.0%90.0%90.0%90.1%90.1%90.1%90.1%90.1%90.2%90.2%90.2%90.2%90.2%90.3%90.3%90.3%90.3%90.3%90.3%90.4%90.4%90.4%90.4%90.4%90.5%90.5%90.5%90.5%90.5%90.6%90.6%90.6%90.6%90.6%90.7%90.7%90.7%90.7%90.7%90.8%90.8%90.8%90.8%90.8%90.8%90.9%90.9%90.9%90.9%90.9%91.0%91.0%91.0%91.0%91.0%91.1%91.1%91.1%91.1%91.1%91.2%91.2%91.2%91.2%91.2%91.3%91.3%91.3%91.3%91.3%91.3%91.4%91.4%91.4%91.4%91.4%91.5%91.5%91.5%91.5%91.5%91.6%91.6%91.6%91.6%91.6%91.7%91.7%91.7%91.7%91.7%91.8%91.8%91.8%91.8%91.8%91.8%91.9%91.9%91.9%91.9%91.9%92.0%92.0%92.0%92.0%92.0%92.1%92.1%92.1%92.1%92.1%92.2%92.2%92.2%92.2%92.2%92.3%92.3%92.3%92.3%92.3%92.3%92.4%92.4%92.4%92.4%92.4%92.5%92.5%92.5%92.5%92.5%92.6%92.6%92.6%92.6%92.6%92.7%92.7%92.7%92.7%92.7%92.8%92.8%92.8%92.8%92.8%92.8%92.9%92.9%92.9%92.9%92.9%93.0%93.0%93.0%93.0%93.0%93.1%93.1%93.1%93.1%93.1%93.2%93.2%93.2%93.2%93.2%93.3%93.3%93.3%93.3%93.3%93.3%93.4%93.4%93.4%93.4%93.4%93.5%93.5%93.5%93.5%93.5%93.6%93.6%93.6%93.6%93.6%93.7%93.7%93.7%93.7%93.7%93.8%93.8%93.8%93.8%93.8%93.8%93.9%93.9%93.9%93.9%93.9%94.0%94.0%94.0%94.0%94.0%94.1%94.1%94.1%94.1%94.1%94.2%94.2%94.2%94.2%94.2%94.2%94.3%94.3%94.3%94.3%94.3%94.4%94.4%94.4%94.4%94.4%94.5%94.5%94.5%94.5%94.5%94.6%94.6%94.6%94.6%94.6%94.7%94.7%94.7%94.7%94.7%94.7%94.8%94.8%94.8%94.8%94.8%94.9%94.9%94.9%94.9%94.9%95.0%95.0%95.0%95.0%95.0%95.1%95.1%95.1%95.1%95.1%95.2%95.2%95.2%95.2%95.2%95.2%95.3%95.3%95.3%95.3%95.3%95.4%95.4%95.4%95.4%95.4%95.5%95.5%95.5%95.5%95.5%95.6%95.6%95.6%95.6%95.6%95.7%95.7%95.7%95.7%95.7%95.7%95.8%95.8%95.8%95.8%95.8%95.9%95.9%95.9%95.9%95.9%96.0%96.0%96.0%96.0%96.0%96.1%96.1%96.1%96.1%96.1%96.2%96.2%96.2%96.2%96.2%96.2%96.3%96.3%96.3%96.3%96.3%96.4%96.4%96.4%96.4%96.4%96.5%96.5%96.5%96.5%96.5%96.6%96.6%96.6%96.6%96.6%96.7%96.7%96.7%96.7%96.7%96.7%96.8%96.8%96.8%96.8%96.8%96.9%96.9%96.9%96.9%96.9%97.0%97.0%97.0%97.0%97.0%97.1%97.1%97.1%97.1%97.1%97.2%97.2%97.2%97.2%97.2%97.2%97.3%97.3%97.3%97.3%97.3%97.4%97.4%97.4%97.4%97.4%97.5%97.5%97.5%97.5%97.5%97.6%97.6%97.6%97.6%97.6%97.7%97.7%97.7%97.7%97.7%97.7%97.8%97.8%97.8%97.8%97.8%97.9%97.9%97.9%97.9%97.9%98.0%98.0%98.0%98.0%98.0%98.1%98.1%98.1%98.1%98.1%98.2%98.2%98.2%98.2%98.2%98.2%98.3%98.3%98.3%98.3%98.3%98.4%98.4%98.4%98.4%98.4%98.5%98.5%98.5%98.5%98.5%98.6%98.6%98.6%98.6%98.6%98.7%98.7%98.7%98.7%98.7%98.7%98.8%98.8%98.8%98.8%98.8%98.9%98.9%98.9%98.9%98.9%99.0%99.0%99.0%99.0%99.0%99.1%99.1%99.1%99.1%99.1%99.2%99.2%99.2%99.2%99.2%99.2%99.3%99.3%99.3%99.3%99.3%99.4%99.4%99.4%99.4%99.4%99.5%99.5%99.5%99.5%99.5%99.6%99.6%99.6%99.6%99.6%99.7%99.7%99.7%99.7%99.7%99.7%99.8%99.8%99.8%99.8%99.8%99.9%99.9%99.9%99.9%99.9%100.0%100.0%100.0%100.0%
INFO flwr 2023-04-26 11:45:31,522 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=30, round_timeout=None)
2023-04-26 11:45:33,802	INFO worker.py:1529 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
INFO flwr 2023-04-26 11:45:37,484 | app.py:179 | Flower VCE: Ray initialized with resources: {'memory': 358042863821.0, 'GPU': 1.0, 'object_store_memory': 157732655923.0, 'CPU': 72.0, 'accelerator_type:A100': 1.0, 'node:145.136.62.9': 1.0}
INFO flwr 2023-04-26 11:45:37,484 | server.py:86 | Initializing global parameters
INFO flwr 2023-04-26 11:45:37,484 | server.py:266 | Using initial parameters provided by strategy
INFO flwr 2023-04-26 11:45:37,484 | server.py:88 | Evaluating initial parameters
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /scratch-local/sunnys.2659640/cifar-10-python.tar.gz
Extracting /scratch-local/sunnys.2659640/cifar-10-python.tar.gz to /scratch-local/sunnys.2659640
Generating unified cifar10 dataset
Class histogram for 0-th partition (alpha=100.0, 10 classes): [256 249 217 265 244 275 235 226 275 258]
INFO flwr 2023-04-26 11:45:42,813 | server.py:91 | initial parameters (loss, other metrics): 2.2996636138916013, {'server_test_acc': 0.1162}
INFO flwr 2023-04-26 11:45:42,813 | server.py:101 | FL starting
DEBUG flwr 2023-04-26 11:45:42,813 | server.py:215 | fit_round 1: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 11:46:24,231 | server.py:229 | fit_round 1 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=3205931)[0m Fitting Client 3
[2m[36m(launch_and_fit pid=3205937)[0m Fitting Client 5
[2m[36m(launch_and_fit pid=3205933)[0m Fitting Client 14
[2m[36m(launch_and_fit pid=3205936)[0m Fitting Client 13
[2m[36m(launch_and_fit pid=3205938)[0m Fitting Client 10
[2m[36m(launch_and_fit pid=3205932)[0m Fitting Client 8
[2m[36m(launch_and_fit pid=3205934)[0m Fitting Client 12
[2m[36m(launch_and_fit pid=3205935)[0m Fitting Client 7
[2m[36m(launch_and_fit pid=3205936)[0m Epoch 5 : loss 2.313119797556024, acc 0.09978947368421053
[2m[36m(launch_and_fit pid=3205934)[0m Epoch 5 : loss 2.023751454001979, acc 0.2
[2m[36m(launch_and_fit pid=3205937)[0m Epoch 5 : loss 2.0868493226703846, acc 0.1848421052631579
[2m[36m(launch_and_fit pid=3205933)[0m Epoch 5 : loss 2.1308547094244705, acc 0.1743157894736842
[2m[36m(launch_and_fit pid=3205931)[0m Epoch 5 : loss 2.121246981169048, acc 0.18442105263157896
[2m[36m(launch_and_fit pid=3205935)[0m Epoch 5 : loss 2.0514905913503547, acc 0.21557894736842106
[2m[36m(launch_and_fit pid=3205932)[0m Epoch 5 : loss 2.04132772064209, acc 0.18821052631578947
[2m[36m(launch_and_fit pid=3205938)[0m Epoch 5 : loss 2.1856823220503956, acc 0.16547368421052633
[2m[36m(launch_and_fit pid=3205936)[0m Epoch 10 : loss 2.3172967585513464, acc 0.09936842105263158
[2m[36m(launch_and_fit pid=3205934)[0m Epoch 10 : loss 1.941408751638312, acc 0.23494736842105263
[2m[36m(launch_and_fit pid=3205937)[0m Epoch 10 : loss 1.9332948094418174, acc 0.23957894736842106
[2m[36m(launch_and_fit pid=3205933)[0m Epoch 10 : loss 1.9614381340428402, acc 0.18357894736842106
[2m[36m(launch_and_fit pid=3205931)[0m Epoch 10 : loss 1.9733288004021896, acc 0.1936842105263158
[2m[36m(launch_and_fit pid=3205932)[0m Epoch 10 : loss 1.8832313617907073, acc 0.2543157894736842
[2m[36m(launch_and_fit pid=3205935)[0m Epoch 10 : loss 1.8646736209267065, acc 0.2690526315789474
[2m[36m(launch_and_fit pid=3205938)[0m Epoch 10 : loss 1.9782268006174188, acc 0.18652631578947368
Performing server side distillation training...
step 100, val_acc : 0.2108
step 200, val_acc : 0.2164
step 300, val_acc : 0.2056
Distillation training stopped at step number : 348
Fusion training loss : 1.0512839179678724, val accuracy : 0.19804022988505748
INFO flwr 2023-04-26 11:49:07,242 | server.py:116 | fit progress: (1, 2.0193208530426023, {'server_test_acc': 0.2062}, 204.42848015000345)
INFO flwr 2023-04-26 11:49:07,242 | server.py:163 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2023-04-26 11:49:07,242 | server.py:215 | fit_round 2: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 11:49:48,650 | server.py:229 | fit_round 2 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=3325508)[0m Fitting Client 5
[2m[36m(launch_and_fit pid=3325510)[0m Fitting Client 6
[2m[36m(launch_and_fit pid=3325507)[0m Fitting Client 11
[2m[36m(launch_and_fit pid=3325509)[0m Fitting Client 17
[2m[36m(launch_and_fit pid=3325506)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=3325511)[0m Fitting Client 8
[2m[36m(launch_and_fit pid=3325518)[0m Fitting Client 13
[2m[36m(launch_and_fit pid=3325519)[0m Fitting Client 10
[2m[36m(launch_and_fit pid=3325508)[0m Epoch 5 : loss 2.117261097155119, acc 0.1848421052631579
[2m[36m(launch_and_fit pid=3325518)[0m Epoch 5 : loss 2.316842469867907, acc 0.10273684210526315
[2m[36m(launch_and_fit pid=3325509)[0m Epoch 5 : loss 2.3101770806563526, acc 0.10863157894736843
[2m[36m(launch_and_fit pid=3325507)[0m Epoch 5 : loss 2.0356583533036083, acc 0.21726315789473685
[2m[36m(launch_and_fit pid=3325506)[0m Epoch 5 : loss 2.0549697390104593, acc 0.21557894736842106
[2m[36m(launch_and_fit pid=3325519)[0m Epoch 5 : loss 2.3078405432450144, acc 0.11831578947368421
[2m[36m(launch_and_fit pid=3325511)[0m Epoch 5 : loss 2.072055669684159, acc 0.17010526315789473
[2m[36m(launch_and_fit pid=3325510)[0m Epoch 5 : loss 2.142588841890034, acc 0.17726315789473684
[2m[36m(launch_and_fit pid=3325508)[0m Epoch 10 : loss 1.9766873068558541, acc 0.18905263157894736
[2m[36m(launch_and_fit pid=3325518)[0m Epoch 10 : loss 2.3133152080335115, acc 0.09094736842105264
[2m[36m(launch_and_fit pid=3325507)[0m Epoch 10 : loss 1.9200117862099095, acc 0.2383157894736842
[2m[36m(launch_and_fit pid=3325509)[0m Epoch 10 : loss 2.307384919015985, acc 0.10147368421052631
[2m[36m(launch_and_fit pid=3325506)[0m Epoch 10 : loss 1.881207051327354, acc 0.2825263157894737
[2m[36m(launch_and_fit pid=3325519)[0m Epoch 10 : loss 2.314011853669819, acc 0.10147368421052631
[2m[36m(launch_and_fit pid=3325511)[0m Epoch 10 : loss 2.0083289746736224, acc 0.18105263157894738
[2m[36m(launch_and_fit pid=3325510)[0m Epoch 10 : loss 1.9847111238178454, acc 0.1751578947368421
Performing server side distillation training...
E0426 11:49:54.571752707 3205424 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): 60000ms
step 100, val_acc : 0.216
step 200, val_acc : 0.2284
step 300, val_acc : 0.2436
step 400, val_acc : 0.2408
Distillation training stopped at step number : 468
Fusion training loss : 0.519750909625083, val accuracy : 0.22782478632478637
INFO flwr 2023-04-26 11:53:33,056 | server.py:116 | fit progress: (2, 2.017958446884155, {'server_test_acc': 0.2447}, 470.24308827900677)
INFO flwr 2023-04-26 11:53:33,057 | server.py:163 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2023-04-26 11:53:33,057 | server.py:215 | fit_round 3: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 11:54:14,877 | server.py:229 | fit_round 3 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=3490312)[0m Fitting Client 17
[2m[36m(launch_and_fit pid=3490313)[0m Fitting Client 16
[2m[36m(launch_and_fit pid=3490315)[0m Fitting Client 2
[2m[36m(launch_and_fit pid=3490362)[0m Fitting Client 4
[2m[36m(launch_and_fit pid=3490317)[0m Fitting Client 7
[2m[36m(launch_and_fit pid=3490361)[0m Fitting Client 6
[2m[36m(launch_and_fit pid=3490314)[0m Fitting Client 5
[2m[36m(launch_and_fit pid=3490316)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=3490312)[0m Epoch 5 : loss 2.028299809506065, acc 0.19073684210526315
[2m[36m(launch_and_fit pid=3490316)[0m Epoch 5 : loss 2.308784228676244, acc 0.11452631578947368
[2m[36m(launch_and_fit pid=3490361)[0m Epoch 5 : loss 2.1410334151418584, acc 0.17726315789473684
[2m[36m(launch_and_fit pid=3490317)[0m Epoch 5 : loss 2.039662977519788, acc 0.1911578947368421
[2m[36m(launch_and_fit pid=3490362)[0m Epoch 5 : loss 2.3114044277793484, acc 0.11157894736842106
[2m[36m(launch_and_fit pid=3490315)[0m Epoch 5 : loss 2.1908740852757504, acc 0.1713684210526316
[2m[36m(launch_and_fit pid=3490314)[0m Epoch 5 : loss 2.031290936118678, acc 0.20757894736842106
[2m[36m(launch_and_fit pid=3490313)[0m Epoch 5 : loss 2.3253948629278884, acc 0.112
[2m[36m(launch_and_fit pid=3490312)[0m Epoch 10 : loss 1.9621745063380192, acc 0.20378947368421052
[2m[36m(launch_and_fit pid=3490316)[0m Epoch 10 : loss 2.306281375282689, acc 0.1128421052631579
[2m[36m(launch_and_fit pid=3490361)[0m Epoch 10 : loss 2.0459722290039064, acc 0.1743157894736842
[2m[36m(launch_and_fit pid=3490317)[0m Epoch 10 : loss 1.9360350052682977, acc 0.20673684210526316
[2m[36m(launch_and_fit pid=3490315)[0m Epoch 10 : loss 1.9788996453536185, acc 0.18989473684210526
[2m[36m(launch_and_fit pid=3490362)[0m Epoch 10 : loss 2.3140808474892065, acc 0.10484210526315789
[2m[36m(launch_and_fit pid=3490314)[0m Epoch 10 : loss 1.9421885295667147, acc 0.23115789473684212
[2m[36m(launch_and_fit pid=3490313)[0m Epoch 10 : loss 2.31447975078382, acc 0.11115789473684211
Performing server side distillation training...
E0426 11:54:18.429191435 3344315 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): 120000ms
step 100, val_acc : 0.1924
step 200, val_acc : 0.1888
step 300, val_acc : 0.1932
E0426 11:57:17.174552642 3519798 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): 240000ms
Distillation training stopped at step number : 395
Fusion training loss : 0.6761984060176566, val accuracy : 0.1824374683544304
INFO flwr 2023-04-26 11:57:27,521 | server.py:116 | fit progress: (3, 2.0921402797698976, {'server_test_acc': 0.1997}, 704.7080782300036)
INFO flwr 2023-04-26 11:57:27,522 | server.py:163 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2023-04-26 11:57:27,522 | server.py:215 | fit_round 4: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 11:58:09,259 | server.py:229 | fit_round 4 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=3635972)[0m Fitting Client 17
[2m[36m(launch_and_fit pid=3635967)[0m Fitting Client 10
[2m[36m(launch_and_fit pid=3635969)[0m Fitting Client 13
[2m[36m(launch_and_fit pid=3635971)[0m Fitting Client 1
[2m[36m(launch_and_fit pid=3635970)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=3635973)[0m Fitting Client 0
[2m[36m(launch_and_fit pid=3635968)[0m Fitting Client 7
[2m[36m(launch_and_fit pid=3635974)[0m Fitting Client 12
[2m[36m(launch_and_fit pid=3635972)[0m Epoch 5 : loss 2.3127553192941765, acc 0.10568421052631578
[2m[36m(launch_and_fit pid=3635970)[0m Epoch 5 : loss 2.1374986371492084, acc 0.168
[2m[36m(launch_and_fit pid=3635969)[0m Epoch 5 : loss 2.0568024079172234, acc 0.18147368421052631
[2m[36m(launch_and_fit pid=3635967)[0m Epoch 5 : loss 2.0154819416246914, acc 0.22063157894736843
[2m[36m(launch_and_fit pid=3635968)[0m Epoch 5 : loss 2.3103823434930097, acc 0.11452631578947368
[2m[36m(launch_and_fit pid=3635971)[0m Epoch 5 : loss 2.00626842538934, acc 0.22526315789473683
[2m[36m(launch_and_fit pid=3635973)[0m Epoch 5 : loss 2.110576898675216, acc 0.18105263157894738
[2m[36m(launch_and_fit pid=3635974)[0m Epoch 5 : loss 2.3015360356381067, acc 0.12126315789473684
[2m[36m(launch_and_fit pid=3635972)[0m Epoch 10 : loss 2.310181012605366, acc 0.10863157894736843
[2m[36m(launch_and_fit pid=3635970)[0m Epoch 10 : loss 1.9666928413792661, acc 0.19915789473684212
[2m[36m(launch_and_fit pid=3635969)[0m Epoch 10 : loss 1.9892056808471679, acc 0.19747368421052633
[2m[36m(launch_and_fit pid=3635967)[0m Epoch 10 : loss 1.8076140052393863, acc 0.2951578947368421
[2m[36m(launch_and_fit pid=3635968)[0m Epoch 10 : loss 2.312420450310958, acc 0.10736842105263159
[2m[36m(launch_and_fit pid=3635971)[0m Epoch 10 : loss 1.9213392137226306, acc 0.26063157894736844
[2m[36m(launch_and_fit pid=3635973)[0m Epoch 10 : loss 1.9443506734747635, acc 0.21052631578947367
[2m[36m(launch_and_fit pid=3635974)[0m Epoch 10 : loss 2.305829544067383, acc 0.11494736842105263
Performing server side distillation training...
step 100, val_acc : 0.1872
step 200, val_acc : 0.2076
step 300, val_acc : 0.2192
Distillation training stopped at step number : 389
Fusion training loss : 0.8205364941688766, val accuracy : 0.20599691516709512
INFO flwr 2023-04-26 12:01:20,883 | server.py:116 | fit progress: (4, 2.0080297174453734, {'server_test_acc': 0.2273}, 938.0700967760058)
INFO flwr 2023-04-26 12:01:20,884 | server.py:163 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2023-04-26 12:01:20,884 | server.py:215 | fit_round 5: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:02:02,423 | server.py:229 | fit_round 5 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=3767864)[0m Fitting Client 10
[2m[36m(launch_and_fit pid=3767865)[0m Fitting Client 12
[2m[36m(launch_and_fit pid=3767866)[0m Fitting Client 8
[2m[36m(launch_and_fit pid=3767868)[0m Fitting Client 14
[2m[36m(launch_and_fit pid=3767869)[0m Fitting Client 6
[2m[36m(launch_and_fit pid=3767867)[0m Fitting Client 2
[2m[36m(launch_and_fit pid=3767871)[0m Fitting Client 9
[2m[36m(launch_and_fit pid=3767870)[0m Fitting Client 11
[2m[36m(launch_and_fit pid=3767864)[0m Epoch 5 : loss 2.0561773392526725, acc 0.17726315789473684
[2m[36m(launch_and_fit pid=3767865)[0m Epoch 5 : loss 1.971653465270996, acc 0.22442105263157894
[2m[36m(launch_and_fit pid=3767867)[0m Epoch 5 : loss 1.9520517493800114, acc 0.24168421052631578
[2m[36m(launch_and_fit pid=3767866)[0m Epoch 5 : loss 2.073277507982756, acc 0.17936842105263157
[2m[36m(launch_and_fit pid=3767869)[0m Epoch 5 : loss 2.310876698544151, acc 0.11536842105263158
[2m[36m(launch_and_fit pid=3767868)[0m Epoch 5 : loss 2.070865519874974, acc 0.18021052631578946
[2m[36m(launch_and_fit pid=3767871)[0m Epoch 5 : loss 2.3069209554571852, acc 0.10778947368421053
[2m[36m(launch_and_fit pid=3767870)[0m Epoch 5 : loss 2.3071484656082957, acc 0.11663157894736842
[2m[36m(launch_and_fit pid=3767864)[0m Epoch 10 : loss 1.9190085019563374, acc 0.1928421052631579
[2m[36m(launch_and_fit pid=3767865)[0m Epoch 10 : loss 1.92752292994449, acc 0.25094736842105264
[2m[36m(launch_and_fit pid=3767867)[0m Epoch 10 : loss 1.8501961918881065, acc 0.2867368421052632
[2m[36m(launch_and_fit pid=3767866)[0m Epoch 10 : loss 1.9220597381591797, acc 0.248
[2m[36m(launch_and_fit pid=3767869)[0m Epoch 10 : loss 2.2781264367354543, acc 0.14778947368421053
[2m[36m(launch_and_fit pid=3767868)[0m Epoch 10 : loss 1.9488223712318822, acc 0.20757894736842106
[2m[36m(launch_and_fit pid=3767871)[0m Epoch 10 : loss 2.3140726760061163, acc 0.11705263157894737
[2m[36m(launch_and_fit pid=3767870)[0m Epoch 10 : loss 2.308866581163908, acc 0.11621052631578947
Performing server side distillation training...
E0426 12:02:06.548416706 3630542 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): 480000ms
step 100, val_acc : 0.2576
step 200, val_acc : 0.2424
step 300, val_acc : 0.2508
Distillation training stopped at step number : 333
Fusion training loss : 0.5672134371312173, val accuracy : 0.24614414414414412
INFO flwr 2023-04-26 12:04:49,376 | server.py:116 | fit progress: (5, 1.9706926818847657, {'server_test_acc': 0.2599}, 1146.5621773650055)
INFO flwr 2023-04-26 12:04:49,376 | server.py:163 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2023-04-26 12:04:49,376 | server.py:215 | fit_round 6: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:05:30,920 | server.py:229 | fit_round 6 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=3883001)[0m Fitting Client 15
[2m[36m(launch_and_fit pid=3883002)[0m Fitting Client 10
[2m[36m(launch_and_fit pid=3883003)[0m Fitting Client 6
[2m[36m(launch_and_fit pid=3883005)[0m Fitting Client 2
[2m[36m(launch_and_fit pid=3883006)[0m Fitting Client 14
[2m[36m(launch_and_fit pid=3883008)[0m Fitting Client 12
[2m[36m(launch_and_fit pid=3883007)[0m Fitting Client 17
[2m[36m(launch_and_fit pid=3883004)[0m Fitting Client 4
[2m[36m(launch_and_fit pid=3883002)[0m Epoch 5 : loss 2.3136121223851256, acc 0.10652631578947368
[2m[36m(launch_and_fit pid=3883001)[0m Epoch 5 : loss 2.055012994063528, acc 0.19073684210526315
[2m[36m(launch_and_fit pid=3883003)[0m Epoch 5 : loss 2.3150515562358653, acc 0.09347368421052632
[2m[36m(launch_and_fit pid=3883007)[0m Epoch 5 : loss 2.013994504828202, acc 0.2231578947368421
[2m[36m(launch_and_fit pid=3883005)[0m Epoch 5 : loss 2.004526841013055, acc 0.1928421052631579
[2m[36m(launch_and_fit pid=3883006)[0m Epoch 5 : loss 2.03671193333676, acc 0.17473684210526316
[2m[36m(launch_and_fit pid=3883004)[0m Epoch 5 : loss 2.3077518402902704, acc 0.12
[2m[36m(launch_and_fit pid=3883008)[0m Epoch 5 : loss 2.2894076381482575, acc 0.13178947368421054
[2m[36m(launch_and_fit pid=3883002)[0m Epoch 10 : loss 2.3135326762952304, acc 0.09473684210526316
[2m[36m(launch_and_fit pid=3883001)[0m Epoch 10 : loss 1.9641629702919408, acc 0.19705263157894737
[2m[36m(launch_and_fit pid=3883003)[0m Epoch 10 : loss 2.312884027581466, acc 0.10568421052631578
[2m[36m(launch_and_fit pid=3883007)[0m Epoch 10 : loss 1.8869499246697676, acc 0.25852631578947366
[2m[36m(launch_and_fit pid=3883005)[0m Epoch 10 : loss 1.8838539946706672, acc 0.22021052631578947
[2m[36m(launch_and_fit pid=3883006)[0m Epoch 10 : loss 1.9483213958740235, acc 0.17389473684210527
[2m[36m(launch_and_fit pid=3883004)[0m Epoch 10 : loss 2.013182409186112, acc 0.1831578947368421
[2m[36m(launch_and_fit pid=3883008)[0m Epoch 10 : loss 1.9684010511699477, acc 0.19957894736842105
Performing server side distillation training...
E0426 12:05:33.154345283 3898513 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): 960000ms
E0426 12:05:55.282321538 3899711 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): 1920000ms
step 100, val_acc : 0.2
step 200, val_acc : 0.222
step 300, val_acc : 0.224
step 400, val_acc : 0.2292
Distillation training stopped at step number : 413
Fusion training loss : 0.2590384319262268, val accuracy : 0.2155544794188862
INFO flwr 2023-04-26 12:08:58,056 | server.py:116 | fit progress: (6, 2.0013978366851806, {'server_test_acc': 0.2301}, 1395.2430643679982)
INFO flwr 2023-04-26 12:08:58,057 | server.py:163 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2023-04-26 12:08:58,057 | server.py:215 | fit_round 7: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:09:39,519 | server.py:229 | fit_round 7 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=4033514)[0m Fitting Client 7
[2m[36m(launch_and_fit pid=4033518)[0m Fitting Client 8
[2m[36m(launch_and_fit pid=4033520)[0m Fitting Client 14
[2m[36m(launch_and_fit pid=4033517)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=4033522)[0m Fitting Client 9
[2m[36m(launch_and_fit pid=4033521)[0m Fitting Client 13
[2m[36m(launch_and_fit pid=4033519)[0m Fitting Client 17
[2m[36m(launch_and_fit pid=4033523)[0m Fitting Client 6
[2m[36m(launch_and_fit pid=4033514)[0m Epoch 5 : loss 2.0935386468987716, acc 0.20926315789473685
[2m[36m(launch_and_fit pid=4033517)[0m Epoch 5 : loss 2.082946045323422, acc 0.18610526315789475
[2m[36m(launch_and_fit pid=4033520)[0m Epoch 5 : loss 2.125634466472425, acc 0.18568421052631578
[2m[36m(launch_and_fit pid=4033518)[0m Epoch 5 : loss 2.2842050949899773, acc 0.13515789473684212
[2m[36m(launch_and_fit pid=4033521)[0m Epoch 5 : loss 2.3170576059441816, acc 0.14484210526315788
[2m[36m(launch_and_fit pid=4033523)[0m Epoch 5 : loss 2.034864725614849, acc 0.20505263157894738
[2m[36m(launch_and_fit pid=4033519)[0m Epoch 5 : loss 2.1173344051963405, acc 0.1928421052631579
[2m[36m(launch_and_fit pid=4033522)[0m Epoch 5 : loss 2.13027255168714, acc 0.16757894736842105
[2m[36m(launch_and_fit pid=4033514)[0m Epoch 10 : loss 1.9649866565905119, acc 0.20673684210526316
[2m[36m(launch_and_fit pid=4033517)[0m Epoch 10 : loss 1.8789651734201531, acc 0.2538947368421053
[2m[36m(launch_and_fit pid=4033520)[0m Epoch 10 : loss 1.9521497939260382, acc 0.22063157894736843
[2m[36m(launch_and_fit pid=4033518)[0m Epoch 10 : loss 2.017567129436292, acc 0.19915789473684212
[2m[36m(launch_and_fit pid=4033521)[0m Epoch 10 : loss 2.0365379767166942, acc 0.16926315789473684
[2m[36m(launch_and_fit pid=4033523)[0m Epoch 10 : loss 1.8893787488435445, acc 0.23073684210526316
[2m[36m(launch_and_fit pid=4033519)[0m Epoch 10 : loss 1.8709496395713405, acc 0.26021052631578945
[2m[36m(launch_and_fit pid=4033522)[0m Epoch 10 : loss 1.8951841992829976, acc 0.2614736842105263
Performing server side distillation training...
step 100, val_acc : 0.2384
step 200, val_acc : 0.2456
E0426 12:11:35.571544495 3912863 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): 3840000ms
step 300, val_acc : 0.2408
Distillation training stopped at step number : 384
Fusion training loss : 0.6904073627859665, val accuracy : 0.23626875
INFO flwr 2023-04-26 12:12:51,303 | server.py:116 | fit progress: (7, 1.9411804056167603, {'server_test_acc': 0.2445}, 1628.489871791011)
INFO flwr 2023-04-26 12:12:51,303 | server.py:163 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2023-04-26 12:12:51,304 | server.py:215 | fit_round 8: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:13:32,941 | server.py:229 | fit_round 8 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=4173855)[0m Fitting Client 11
[2m[36m(launch_and_fit pid=4173860)[0m Fitting Client 1
[2m[36m(launch_and_fit pid=4173858)[0m Fitting Client 15
[2m[36m(launch_and_fit pid=4173862)[0m Fitting Client 0
[2m[36m(launch_and_fit pid=4173859)[0m Fitting Client 16
[2m[36m(launch_and_fit pid=4173856)[0m Fitting Client 7
[2m[36m(launch_and_fit pid=4173857)[0m Fitting Client 4
[2m[36m(launch_and_fit pid=4173861)[0m Fitting Client 12
[2m[36m(launch_and_fit pid=4173855)[0m Epoch 5 : loss 2.310188442029451, acc 0.10778947368421053
[2m[36m(launch_and_fit pid=4173862)[0m Epoch 5 : loss 2.024402028937089, acc 0.19157894736842104
[2m[36m(launch_and_fit pid=4173858)[0m Epoch 5 : loss 2.040111482720626, acc 0.192
[2m[36m(launch_and_fit pid=4173857)[0m Epoch 5 : loss 2.192220847280402, acc 0.16042105263157894
[2m[36m(launch_and_fit pid=4173856)[0m Epoch 5 : loss 2.0138398421438115, acc 0.19957894736842105
[2m[36m(launch_and_fit pid=4173860)[0m Epoch 5 : loss 2.090209671823602, acc 0.1726315789473684
[2m[36m(launch_and_fit pid=4173859)[0m Epoch 5 : loss 2.016442945781507, acc 0.18526315789473685
[2m[36m(launch_and_fit pid=4173861)[0m Epoch 5 : loss 2.0593756902594316, acc 0.2
[2m[36m(launch_and_fit pid=4173855)[0m Epoch 10 : loss 2.294442362735146, acc 0.11705263157894737
[2m[36m(launch_and_fit pid=4173862)[0m Epoch 10 : loss 1.954634825455515, acc 0.19452631578947369
[2m[36m(launch_and_fit pid=4173858)[0m Epoch 10 : loss 1.9537259160092002, acc 0.23326315789473684
[2m[36m(launch_and_fit pid=4173857)[0m Epoch 10 : loss 2.0043517094662313, acc 0.1936842105263158
[2m[36m(launch_and_fit pid=4173856)[0m Epoch 10 : loss 1.9949762408607885, acc 0.18273684210526317
[2m[36m(launch_and_fit pid=4173860)[0m Epoch 10 : loss 2.005863170824553, acc 0.21642105263157896
[2m[36m(launch_and_fit pid=4173859)[0m Epoch 10 : loss 1.91171515735827, acc 0.23157894736842105
[2m[36m(launch_and_fit pid=4173861)[0m Epoch 10 : loss 1.9827270266884252, acc 0.22105263157894736
Performing server side distillation training...
E0426 12:13:34.075370771 4189346 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): 7680000ms
step 100, val_acc : 0.2136
step 200, val_acc : 0.1968
Distillation training stopped at step number : 251
Fusion training loss : 0.28535662365862097, val accuracy : 0.20254023904382468
INFO flwr 2023-04-26 12:15:39,762 | server.py:116 | fit progress: (8, 1.9844856525421142, {'server_test_acc': 0.2013}, 1796.9489583880058)
INFO flwr 2023-04-26 12:15:39,763 | server.py:163 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2023-04-26 12:15:39,763 | server.py:215 | fit_round 9: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:16:21,131 | server.py:229 | fit_round 9 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=71193)[0m Fitting Client 4
[2m[36m(launch_and_fit pid=71194)[0m Fitting Client 3
[2m[36m(launch_and_fit pid=71195)[0m Fitting Client 13
[2m[36m(launch_and_fit pid=71198)[0m Fitting Client 6
[2m[36m(launch_and_fit pid=71199)[0m Fitting Client 14
[2m[36m(launch_and_fit pid=71200)[0m Fitting Client 9
[2m[36m(launch_and_fit pid=71196)[0m Fitting Client 5
[2m[36m(launch_and_fit pid=71197)[0m Fitting Client 2
[2m[36m(launch_and_fit pid=71193)[0m Epoch 5 : loss 2.052876683285362, acc 0.18694736842105264
[2m[36m(launch_and_fit pid=71200)[0m Epoch 5 : loss 2.0842567291259764, acc 0.17642105263157895
[2m[36m(launch_and_fit pid=71195)[0m Epoch 5 : loss 2.176583232277318, acc 0.17178947368421052
[2m[36m(launch_and_fit pid=71197)[0m Epoch 5 : loss 2.1124392411081416, acc 0.18442105263157896
[2m[36m(launch_and_fit pid=71198)[0m Epoch 5 : loss 2.3142116137052837, acc 0.10526315789473684
[2m[36m(launch_and_fit pid=71196)[0m Epoch 5 : loss 2.279699064957468, acc 0.1414736842105263
[2m[36m(launch_and_fit pid=71194)[0m Epoch 5 : loss 2.309863710102282, acc 0.09389473684210527
[2m[36m(launch_and_fit pid=71199)[0m Epoch 5 : loss 2.313245943571392, acc 0.09936842105263158
[2m[36m(launch_and_fit pid=71193)[0m Epoch 10 : loss 1.9317658727545488, acc 0.19621052631578947
[2m[36m(launch_and_fit pid=71200)[0m Epoch 10 : loss 2.0501932373046876, acc 0.18989473684210526
[2m[36m(launch_and_fit pid=71195)[0m Epoch 10 : loss 2.0226493839464688, acc 0.18568421052631578
[2m[36m(launch_and_fit pid=71197)[0m Epoch 10 : loss 1.9626573566637542, acc 0.19915789473684212
[2m[36m(launch_and_fit pid=71198)[0m Epoch 10 : loss 2.3120912106162623, acc 0.11115789473684211
[2m[36m(launch_and_fit pid=71196)[0m Epoch 10 : loss 1.9907128352115029, acc 0.21642105263157896
[2m[36m(launch_and_fit pid=71194)[0m Epoch 10 : loss 2.3134369000886617, acc 0.09726315789473684
[2m[36m(launch_and_fit pid=71199)[0m Epoch 10 : loss 2.3989840340865287, acc 0.11452631578947368
Performing server side distillation training...
step 100, val_acc : 0.1828
step 200, val_acc : 0.1876
step 300, val_acc : 0.2104
E0426 12:19:06.024153814  185626 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): 15360000ms
step 400, val_acc : 0.2004
Distillation training stopped at step number : 479
Fusion training loss : 0.5237865525381425, val accuracy : 0.19286012526096033
INFO flwr 2023-04-26 12:20:22,036 | server.py:116 | fit progress: (9, 2.101990392112732, {'server_test_acc': 0.1946}, 2079.2225364600017)
INFO flwr 2023-04-26 12:20:22,036 | server.py:163 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2023-04-26 12:20:22,036 | server.py:215 | fit_round 10: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:21:03,862 | server.py:229 | fit_round 10 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=230625)[0m Fitting Client 16
[2m[36m(launch_and_fit pid=230630)[0m Fitting Client 3
[2m[36m(launch_and_fit pid=230626)[0m Fitting Client 14
[2m[36m(launch_and_fit pid=230627)[0m Fitting Client 8
[2m[36m(launch_and_fit pid=230632)[0m Fitting Client 17
[2m[36m(launch_and_fit pid=230628)[0m Fitting Client 0
[2m[36m(launch_and_fit pid=230631)[0m Fitting Client 12
[2m[36m(launch_and_fit pid=230629)[0m Fitting Client 10
[2m[36m(launch_and_fit pid=230625)[0m Epoch 5 : loss 2.1651166012412624, acc 0.18526315789473685
[2m[36m(launch_and_fit pid=230630)[0m Epoch 5 : loss 2.1654559334202816, acc 0.1726315789473684
[2m[36m(launch_and_fit pid=230632)[0m Epoch 5 : loss 2.110611378318385, acc 0.1713684210526316
[2m[36m(launch_and_fit pid=230628)[0m Epoch 5 : loss 2.008246492084704, acc 0.21221052631578946
[2m[36m(launch_and_fit pid=230631)[0m Epoch 5 : loss 2.3020281179327715, acc 0.10778947368421053
[2m[36m(launch_and_fit pid=230629)[0m Epoch 5 : loss 2.1118263292814556, acc 0.1713684210526316
[2m[36m(launch_and_fit pid=230626)[0m Epoch 5 : loss 2.013483382375617, acc 0.2168421052631579
[2m[36m(launch_and_fit pid=230627)[0m Epoch 5 : loss 2.304568952058491, acc 0.11873684210526315
[2m[36m(launch_and_fit pid=230625)[0m Epoch 10 : loss 2.0179803213822214, acc 0.18947368421052632
[2m[36m(launch_and_fit pid=230630)[0m Epoch 10 : loss 2.0203547981663754, acc 0.18905263157894736
[2m[36m(launch_and_fit pid=230632)[0m Epoch 10 : loss 1.9676353205630654, acc 0.21010526315789474
[2m[36m(launch_and_fit pid=230628)[0m Epoch 10 : loss 1.9136200200131066, acc 0.22778947368421051
[2m[36m(launch_and_fit pid=230629)[0m Epoch 10 : loss 1.9235159610949064, acc 0.19831578947368422
[2m[36m(launch_and_fit pid=230626)[0m Epoch 10 : loss 1.8361744143837377, acc 0.2576842105263158
[2m[36m(launch_and_fit pid=230627)[0m Epoch 10 : loss 2.309189751876028, acc 0.1191578947368421
[2m[36m(launch_and_fit pid=230631)[0m Epoch 10 : loss 2.3039512995669718, acc 0.10778947368421053
Performing server side distillation training...
E0426 12:21:07.560692079  185900 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): 30720000ms
E0426 12:21:31.443721272  248235 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): 61440000ms
step 100, val_acc : 0.1752
step 200, val_acc : 0.1848
step 300, val_acc : 0.2112
step 400, val_acc : 0.21
step 500, val_acc : 0.2084
Distillation training stopped at step number : 500
Fusion training loss : 0.6175587086603046, val accuracy : 0.1939072
INFO flwr 2023-04-26 12:25:16,303 | server.py:116 | fit progress: (10, 2.0508681465148926, {'server_test_acc': 0.2107}, 2373.4892458530085)
INFO flwr 2023-04-26 12:25:16,303 | server.py:163 | evaluate_round 10: no clients selected, cancel
DEBUG flwr 2023-04-26 12:25:16,303 | server.py:215 | fit_round 11: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:25:57,566 | server.py:229 | fit_round 11 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=458660)[0m Fitting Client 8
[2m[36m(launch_and_fit pid=458663)[0m Fitting Client 3
[2m[36m(launch_and_fit pid=458665)[0m Fitting Client 9
[2m[36m(launch_and_fit pid=458667)[0m Fitting Client 2
[2m[36m(launch_and_fit pid=458662)[0m Fitting Client 10
[2m[36m(launch_and_fit pid=458664)[0m Fitting Client 13
[2m[36m(launch_and_fit pid=458666)[0m Fitting Client 7
[2m[36m(launch_and_fit pid=458668)[0m Fitting Client 0
[2m[36m(launch_and_fit pid=458660)[0m Epoch 5 : loss 2.0353092402408, acc 0.21642105263157896
[2m[36m(launch_and_fit pid=458665)[0m Epoch 5 : loss 2.016271065962942, acc 0.1936842105263158
[2m[36m(launch_and_fit pid=458663)[0m Epoch 5 : loss 2.2635746090537623, acc 0.13726315789473684
[2m[36m(launch_and_fit pid=458667)[0m Epoch 5 : loss 2.185338910554585, acc 0.17894736842105263
[2m[36m(launch_and_fit pid=458664)[0m Epoch 5 : loss 2.2154519476639596, acc 0.17894736842105263
[2m[36m(launch_and_fit pid=458662)[0m Epoch 5 : loss 2.05538974882427, acc 0.19915789473684212
[2m[36m(launch_and_fit pid=458666)[0m Epoch 5 : loss 1.9706147838391757, acc 0.208
[2m[36m(launch_and_fit pid=458668)[0m Epoch 5 : loss 2.0377986514442847, acc 0.17684210526315788
[2m[36m(launch_and_fit pid=458660)[0m Epoch 10 : loss 1.8543713218287419, acc 0.2488421052631579
[2m[36m(launch_and_fit pid=458665)[0m Epoch 10 : loss 1.9256961059570312, acc 0.232
[2m[36m(launch_and_fit pid=458663)[0m Epoch 10 : loss 1.9919589442202918, acc 0.1823157894736842
[2m[36m(launch_and_fit pid=458667)[0m Epoch 10 : loss 1.972306367171438, acc 0.1966315789473684
[2m[36m(launch_and_fit pid=458664)[0m Epoch 10 : loss 1.9609333427830746, acc 0.21263157894736842
[2m[36m(launch_and_fit pid=458662)[0m Epoch 10 : loss 1.9426911689356754, acc 0.19452631578947369
[2m[36m(launch_and_fit pid=458666)[0m Epoch 10 : loss 1.9560927557694285, acc 0.23873684210526316
[2m[36m(launch_and_fit pid=458668)[0m Epoch 10 : loss 1.9488292441117137, acc 0.2016842105263158
Performing server side distillation training...
E0426 12:26:02.006695172  262401 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): 122880000ms
step 100, val_acc : 0.2
step 200, val_acc : 0.2044
Distillation training stopped at step number : 253
Fusion training loss : 0.9526118401717762, val accuracy : 0.20538339920948617
INFO flwr 2023-04-26 12:28:07,110 | server.py:116 | fit progress: (11, 1.9629183238983154, {'server_test_acc': 0.2089}, 2544.2962366449938)
INFO flwr 2023-04-26 12:28:07,110 | server.py:163 | evaluate_round 11: no clients selected, cancel
DEBUG flwr 2023-04-26 12:28:07,110 | server.py:215 | fit_round 12: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:28:49,014 | server.py:229 | fit_round 12 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=550019)[0m Fitting Client 8
[2m[36m(launch_and_fit pid=550020)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=550021)[0m Fitting Client 16
[2m[36m(launch_and_fit pid=550020)[0m 
[2m[36m(launch_and_fit pid=550086)[0m Fitting Client 10
[2m[36m(launch_and_fit pid=550147)[0m Fitting Client 4
[2m[36m(launch_and_fit pid=550091)[0m Fitting Client 5
[2m[36m(launch_and_fit pid=550148)[0m Fitting Client 13
[2m[36m(launch_and_fit pid=550146)[0m Fitting Client 3
[2m[36m(launch_and_fit pid=550019)[0m Epoch 5 : loss 2.0453126802946393, acc 0.19157894736842104
[2m[36m(launch_and_fit pid=550020)[0m Epoch 5 : loss 2.0470990030389085, acc 0.18357894736842106
[2m[36m(launch_and_fit pid=550147)[0m Epoch 5 : loss 2.311677380210475, acc 0.11031578947368421
[2m[36m(launch_and_fit pid=550021)[0m Epoch 5 : loss 2.089090779354698, acc 0.19242105263157894
[2m[36m(launch_and_fit pid=550086)[0m Epoch 5 : loss 2.1060668174342103, acc 0.19452631578947369
[2m[36m(launch_and_fit pid=550146)[0m Epoch 5 : loss 2.088018837376645, acc 0.16505263157894737
[2m[36m(launch_and_fit pid=550091)[0m Epoch 5 : loss 2.0268475791529603, acc 0.19915789473684212
[2m[36m(launch_and_fit pid=550148)[0m Epoch 5 : loss 2.04993683704577, acc 0.18989473684210526
[2m[36m(launch_and_fit pid=550019)[0m Epoch 10 : loss 1.9753952576486689, acc 0.2016842105263158
[2m[36m(launch_and_fit pid=550020)[0m Epoch 10 : loss 1.9882629121479236, acc 0.17642105263157895
[2m[36m(launch_and_fit pid=550147)[0m Epoch 10 : loss 2.3116349776418588, acc 0.11705263157894737
[2m[36m(launch_and_fit pid=550021)[0m Epoch 10 : loss 1.9569549223247327, acc 0.19789473684210526
[2m[36m(launch_and_fit pid=550086)[0m Epoch 10 : loss 1.9460914338764392, acc 0.22021052631578947
[2m[36m(launch_and_fit pid=550146)[0m Epoch 10 : loss 1.9540365825452302, acc 0.20505263157894738
[2m[36m(launch_and_fit pid=550091)[0m Epoch 10 : loss 1.9688628861276727, acc 0.22610526315789473
[2m[36m(launch_and_fit pid=550148)[0m Epoch 10 : loss 1.9758121980365955, acc 0.19705263157894737
Performing server side distillation training...
E0426 12:28:59.701730362  476592 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): 245760000ms
step 100, val_acc : 0.2148
step 200, val_acc : 0.2012
step 300, val_acc : 0.2224
Distillation training stopped at step number : 303
Fusion training loss : 0.6032201238837179, val accuracy : 0.2092237623762376
INFO flwr 2023-04-26 12:31:25,259 | server.py:116 | fit progress: (12, 2.035896958351135, {'server_test_acc': 0.2169}, 2742.445412436995)
INFO flwr 2023-04-26 12:31:25,259 | server.py:163 | evaluate_round 12: no clients selected, cancel
DEBUG flwr 2023-04-26 12:31:25,259 | server.py:215 | fit_round 13: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:32:07,345 | server.py:229 | fit_round 13 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=656818)[0m Fitting Client 16
[2m[36m(launch_and_fit pid=656821)[0m Fitting Client 4
[2m[36m(launch_and_fit pid=656819)[0m Fitting Client 5
[2m[36m(launch_and_fit pid=656822)[0m Fitting Client 6
[2m[36m(launch_and_fit pid=656820)[0m Fitting Client 11
[2m[36m(launch_and_fit pid=656823)[0m Fitting Client 12
[2m[36m(launch_and_fit pid=656825)[0m Fitting Client 14
[2m[36m(launch_and_fit pid=656824)[0m Fitting Client 8
[2m[36m(launch_and_fit pid=656818)[0m Epoch 5 : loss 2.3080307962517987, acc 0.1031578947368421
[2m[36m(launch_and_fit pid=656822)[0m Epoch 5 : loss 2.1295997623644376, acc 0.1637894736842105
[2m[36m(launch_and_fit pid=656820)[0m Epoch 5 : loss 2.0538565914756375, acc 0.22694736842105262
[2m[36m(launch_and_fit pid=656823)[0m Epoch 5 : loss 2.0714340547260486, acc 0.1957894736842105
[2m[36m(launch_and_fit pid=656821)[0m Epoch 5 : loss 2.311623456453022, acc 0.11031578947368421
[2m[36m(launch_and_fit pid=656824)[0m Epoch 5 : loss 2.308528446398283, acc 0.10526315789473684
[2m[36m(launch_and_fit pid=656825)[0m Epoch 5 : loss 2.064572369224147, acc 0.17936842105263157
[2m[36m(launch_and_fit pid=656819)[0m Epoch 5 : loss 2.3265887005454617, acc 0.10905263157894737
[2m[36m(launch_and_fit pid=656818)[0m Epoch 10 : loss 2.312125641672235, acc 0.10021052631578947
[2m[36m(launch_and_fit pid=656822)[0m Epoch 10 : loss 1.999671531275699, acc 0.184
[2m[36m(launch_and_fit pid=656820)[0m Epoch 10 : loss 1.905907231782612, acc 0.2648421052631579
[2m[36m(launch_and_fit pid=656823)[0m Epoch 10 : loss 1.9437946022435237, acc 0.22821052631578947
[2m[36m(launch_and_fit pid=656821)[0m Epoch 10 : loss 2.312988763909591, acc 0.10147368421052631
[2m[36m(launch_and_fit pid=656824)[0m Epoch 10 : loss 2.3063846427515933, acc 0.10484210526315789
[2m[36m(launch_and_fit pid=656825)[0m Epoch 10 : loss 1.9550644952874434, acc 0.22021052631578947
[2m[36m(launch_and_fit pid=656819)[0m Epoch 10 : loss 2.1592827622263053, acc 0.17726315789473684
Performing server side distillation training...
E0426 12:32:08.325438335  571603 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): 491520000ms
step 100, val_acc : 0.2008
step 200, val_acc : 0.2088
step 300, val_acc : 0.2112
step 400, val_acc : 0.2148
Distillation training stopped at step number : 459
Fusion training loss : 0.3274571305477671, val accuracy : 0.21087494553376904
INFO flwr 2023-04-26 12:36:02,843 | server.py:116 | fit progress: (13, 2.0475500299453735, {'server_test_acc': 0.2103}, 3020.0296317140164)
INFO flwr 2023-04-26 12:36:02,843 | server.py:163 | evaluate_round 13: no clients selected, cancel
DEBUG flwr 2023-04-26 12:36:02,843 | server.py:215 | fit_round 14: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:36:44,653 | server.py:229 | fit_round 14 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=809944)[0m Fitting Client 10
[2m[36m(launch_and_fit pid=809947)[0m Fitting Client 0
[2m[36m(launch_and_fit pid=809946)[0m Fitting Client 19
[2m[36m(launch_and_fit pid=809945)[0m Fitting Client 15
[2m[36m(launch_and_fit pid=809949)[0m Fitting Client 14
[2m[36m(launch_and_fit pid=809948)[0m Fitting Client 3
[2m[36m(launch_and_fit pid=809950)[0m Fitting Client 5
[2m[36m(launch_and_fit pid=809951)[0m Fitting Client 12
[2m[36m(launch_and_fit pid=809947)[0m Epoch 5 : loss 2.1842456143027857, acc 0.16210526315789472
[2m[36m(launch_and_fit pid=809944)[0m Epoch 5 : loss 2.069537053961503, acc 0.17557894736842106
[2m[36m(launch_and_fit pid=809949)[0m Epoch 5 : loss 2.1289483273154812, acc 0.18652631578947368
[2m[36m(launch_and_fit pid=809948)[0m Epoch 5 : loss 2.169314547890111, acc 0.18147368421052631
[2m[36m(launch_and_fit pid=809946)[0m Epoch 5 : loss 2.09351691517077, acc 0.152
[2m[36m(launch_and_fit pid=809950)[0m Epoch 5 : loss 2.0434318831594367, acc 0.1848421052631579
[2m[36m(launch_and_fit pid=809945)[0m Epoch 5 : loss 2.309754238730983, acc 0.11494736842105263
[2m[36m(launch_and_fit pid=809951)[0m Epoch 5 : loss 2.037162130255448, acc 0.18778947368421053
[2m[36m(launch_and_fit pid=809947)[0m Epoch 10 : loss 1.966520841498124, acc 0.1911578947368421
[2m[36m(launch_and_fit pid=809944)[0m Epoch 10 : loss 1.9631420376426296, acc 0.20126315789473684
[2m[36m(launch_and_fit pid=809949)[0m Epoch 10 : loss 1.8728089535361843, acc 0.2383157894736842
[2m[36m(launch_and_fit pid=809948)[0m Epoch 10 : loss 1.9402961959838867, acc 0.2265263157894737
[2m[36m(launch_and_fit pid=809946)[0m Epoch 10 : loss 2.089904441833496, acc 0.17894736842105263
[2m[36m(launch_and_fit pid=809945)[0m Epoch 10 : loss 2.310298166375411, acc 0.10526315789473684
[2m[36m(launch_and_fit pid=809950)[0m Epoch 10 : loss 1.9761404932925575, acc 0.184
[2m[36m(launch_and_fit pid=809951)[0m Epoch 10 : loss 1.942095972964638, acc 0.20926315789473685
Performing server side distillation training...
E0426 12:36:45.833243524  825439 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): 983040000ms
step 100, val_acc : 0.2168
step 200, val_acc : 0.2104
Distillation training stopped at step number : 293
Fusion training loss : 0.3120866559395001, val accuracy : 0.22052423208191124
INFO flwr 2023-04-26 12:39:16,506 | server.py:116 | fit progress: (14, 2.015881406402588, {'server_test_acc': 0.2194}, 3213.6922980800155)
INFO flwr 2023-04-26 12:39:16,506 | server.py:163 | evaluate_round 14: no clients selected, cancel
DEBUG flwr 2023-04-26 12:39:16,506 | server.py:215 | fit_round 15: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:39:58,251 | server.py:229 | fit_round 15 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=934201)[0m Fitting Client 9
[2m[36m(launch_and_fit pid=934206)[0m Fitting Client 11
[2m[36m(launch_and_fit pid=934205)[0m Fitting Client 2
[2m[36m(launch_and_fit pid=934203)[0m Fitting Client 1
[2m[36m(launch_and_fit pid=934204)[0m Fitting Client 7
[2m[36m(launch_and_fit pid=934202)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=934207)[0m Fitting Client 17
[2m[36m(launch_and_fit pid=934208)[0m Fitting Client 16
[2m[36m(launch_and_fit pid=934202)[0m Epoch 5 : loss 2.1930840309544615, acc 0.16673684210526316
[2m[36m(launch_and_fit pid=934203)[0m Epoch 5 : loss 2.122070687143426, acc 0.18189473684210528
[2m[36m(launch_and_fit pid=934204)[0m Epoch 5 : loss 2.0505080080534284, acc 0.19789473684210526
[2m[36m(launch_and_fit pid=934205)[0m Epoch 5 : loss 2.0256744384765626, acc 0.20463157894736841
[2m[36m(launch_and_fit pid=934201)[0m Epoch 5 : loss 2.3068413126092207, acc 0.09389473684210527
[2m[36m(launch_and_fit pid=934207)[0m Epoch 5 : loss 2.1994206771850586, acc 0.1688421052631579
[2m[36m(launch_and_fit pid=934206)[0m Epoch 5 : loss 2.021241315339741, acc 0.2033684210526316
[2m[36m(launch_and_fit pid=934208)[0m Epoch 5 : loss 2.0922416430021586, acc 0.19452631578947369
[2m[36m(launch_and_fit pid=934202)[0m Epoch 10 : loss 1.927574772081877, acc 0.18526315789473685
[2m[36m(launch_and_fit pid=934203)[0m Epoch 10 : loss 1.9632941155684622, acc 0.20842105263157895
[2m[36m(launch_and_fit pid=934204)[0m Epoch 10 : loss 1.9539922979254472, acc 0.19915789473684212
[2m[36m(launch_and_fit pid=934205)[0m Epoch 10 : loss 1.9303637165270353, acc 0.20673684210526316
[2m[36m(launch_and_fit pid=934201)[0m Epoch 10 : loss 2.3063370867277446, acc 0.11578947368421053
[2m[36m(launch_and_fit pid=934206)[0m Epoch 10 : loss 2.01686271185624, acc 0.20378947368421052
[2m[36m(launch_and_fit pid=934207)[0m Epoch 10 : loss 1.9927133724814967, acc 0.20757894736842106
[2m[36m(launch_and_fit pid=934208)[0m Epoch 10 : loss 1.9007300431100946, acc 0.25263157894736843
Performing server side distillation training...
E0426 12:39:59.767910945  826006 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): 1966080000ms
step 100, val_acc : 0.2268
step 200, val_acc : 0.2128
E0426 12:42:30.016559543  950948 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
step 300, val_acc : 0.2236
E0426 12:42:37.965537687 1043237 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
Distillation training stopped at step number : 326
Fusion training loss : 0.5048863270599966, val accuracy : 0.21619386503067486
INFO flwr 2023-04-26 12:42:47,153 | server.py:116 | fit progress: (15, 2.0029696313858034, {'server_test_acc': 0.2322}, 3424.3394656540186)
INFO flwr 2023-04-26 12:42:47,153 | server.py:163 | evaluate_round 15: no clients selected, cancel
DEBUG flwr 2023-04-26 12:42:47,153 | server.py:215 | fit_round 16: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:43:28,639 | server.py:229 | fit_round 16 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=1047928)[0m Fitting Client 4
[2m[36m(launch_and_fit pid=1047929)[0m Fitting Client 2
[2m[36m(launch_and_fit pid=1047927)[0m Fitting Client 17
[2m[36m(launch_and_fit pid=1047930)[0m Fitting Client 8
[2m[36m(launch_and_fit pid=1047931)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=1047934)[0m Fitting Client 16
[2m[36m(launch_and_fit pid=1047933)[0m Fitting Client 15
[2m[36m(launch_and_fit pid=1047932)[0m Fitting Client 19
[2m[36m(launch_and_fit pid=1047928)[0m Epoch 5 : loss 2.3112992698267885, acc 0.11957894736842105
[2m[36m(launch_and_fit pid=1047929)[0m Epoch 5 : loss 2.310056938572934, acc 0.10231578947368421
[2m[36m(launch_and_fit pid=1047930)[0m Epoch 5 : loss 2.0057236472681947, acc 0.19157894736842104
[2m[36m(launch_and_fit pid=1047927)[0m Epoch 5 : loss 2.011557199578536, acc 0.21136842105263157
[2m[36m(launch_and_fit pid=1047932)[0m Epoch 5 : loss 1.8014828021400853, acc 0.30189473684210527
[2m[36m(launch_and_fit pid=1047934)[0m Epoch 5 : loss 2.311004674008018, acc 0.11494736842105263
[2m[36m(launch_and_fit pid=1047933)[0m Epoch 5 : loss 2.311804528085809, acc 0.10821052631578948
[2m[36m(launch_and_fit pid=1047931)[0m Epoch 5 : loss 2.0734557707937142, acc 0.16673684210526316
[2m[36m(launch_and_fit pid=1047928)[0m Epoch 10 : loss 2.422367805882504, acc 0.11663157894736842
[2m[36m(launch_and_fit pid=1047929)[0m Epoch 10 : loss 2.36328376569246, acc 0.10610526315789473
[2m[36m(launch_and_fit pid=1047930)[0m Epoch 10 : loss 1.9472151461149516, acc 0.20884210526315788
[2m[36m(launch_and_fit pid=1047927)[0m Epoch 10 : loss 1.8908634603399979, acc 0.25094736842105264
[2m[36m(launch_and_fit pid=1047932)[0m Epoch 10 : loss 1.6948276222630552, acc 0.35326315789473683
[2m[36m(launch_and_fit pid=1047934)[0m Epoch 10 : loss 2.311047849956312, acc 0.10947368421052632
[2m[36m(launch_and_fit pid=1047933)[0m Epoch 10 : loss 2.306325408935547, acc 0.11452631578947368
[2m[36m(launch_and_fit pid=1047931)[0m Epoch 10 : loss 1.9626692802027652, acc 0.19326315789473683
Performing server side distillation training...
step 100, val_acc : 0.1772
step 200, val_acc : 0.1788
Distillation training stopped at step number : 251
Fusion training loss : 1.6016554141424566, val accuracy : 0.17824701195219125
INFO flwr 2023-04-26 12:45:39,726 | server.py:116 | fit progress: (16, 2.274468712234497, {'server_test_acc': 0.1701}, 3596.9130991940037)
INFO flwr 2023-04-26 12:45:39,727 | server.py:163 | evaluate_round 16: no clients selected, cancel
DEBUG flwr 2023-04-26 12:45:39,727 | server.py:215 | fit_round 17: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:46:21,319 | server.py:229 | fit_round 17 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=1138787)[0m Fitting Client 16
[2m[36m(launch_and_fit pid=1138792)[0m Fitting Client 17
[2m[36m(launch_and_fit pid=1138796)[0m Fitting Client 9
[2m[36m(launch_and_fit pid=1138793)[0m Fitting Client 13
[2m[36m(launch_and_fit pid=1138798)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=1138794)[0m Fitting Client 10
[2m[36m(launch_and_fit pid=1138795)[0m Fitting Client 6
[2m[36m(launch_and_fit pid=1138797)[0m Fitting Client 19
[2m[36m(launch_and_fit pid=1138787)[0m Epoch 5 : loss 2.1563653564453125, acc 0.1696842105263158
[2m[36m(launch_and_fit pid=1138793)[0m Epoch 5 : loss 2.064629839043868, acc 0.1911578947368421
[2m[36m(launch_and_fit pid=1138794)[0m Epoch 5 : loss 2.051995326795076, acc 0.21136842105263157
[2m[36m(launch_and_fit pid=1138795)[0m Epoch 5 : loss 2.253499496861508, acc 0.1423157894736842
[2m[36m(launch_and_fit pid=1138796)[0m Epoch 5 : loss 2.3085668921219673, acc 0.11663157894736842
[2m[36m(launch_and_fit pid=1138792)[0m Epoch 5 : loss 2.22815952903346, acc 0.152
[2m[36m(launch_and_fit pid=1138797)[0m Epoch 5 : loss 1.7724543424907484, acc 0.33052631578947367
[2m[36m(launch_and_fit pid=1138798)[0m Epoch 5 : loss 2.0961229697779604, acc 0.17684210526315788
[2m[36m(launch_and_fit pid=1138787)[0m Epoch 10 : loss 2.0314624545448705, acc 0.184
[2m[36m(launch_and_fit pid=1138793)[0m Epoch 10 : loss 1.995781165273566, acc 0.21305263157894735
[2m[36m(launch_and_fit pid=1138794)[0m Epoch 10 : loss 1.9538156272486638, acc 0.20421052631578948
[2m[36m(launch_and_fit pid=1138795)[0m Epoch 10 : loss 2.0267232798526162, acc 0.1911578947368421
[2m[36m(launch_and_fit pid=1138796)[0m Epoch 10 : loss 2.305559525339227, acc 0.11747368421052631
[2m[36m(launch_and_fit pid=1138792)[0m Epoch 10 : loss 2.0583778317100125, acc 0.16463157894736843
[2m[36m(launch_and_fit pid=1138797)[0m Epoch 10 : loss 1.6403162227429842, acc 0.38273684210526315
[2m[36m(launch_and_fit pid=1138798)[0m Epoch 10 : loss 1.962043511641653, acc 0.18905263157894736
Performing server side distillation training...
E0426 12:46:24.071325227 1155140 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
step 100, val_acc : 0.1788
step 200, val_acc : 0.1612
step 300, val_acc : 0.1752
Distillation training stopped at step number : 309
Fusion training loss : 0.9251552201976282, val accuracy : 0.17601165048543688
INFO flwr 2023-04-26 12:49:02,496 | server.py:116 | fit progress: (17, 2.115663186645508, {'server_test_acc': 0.1817}, 3799.683062119002)
INFO flwr 2023-04-26 12:49:02,497 | server.py:163 | evaluate_round 17: no clients selected, cancel
DEBUG flwr 2023-04-26 12:49:02,497 | server.py:215 | fit_round 18: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:49:44,315 | server.py:229 | fit_round 18 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=1246680)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=1246679)[0m Fitting Client 11
[2m[36m(launch_and_fit pid=1246678)[0m Fitting Client 14
[2m[36m(launch_and_fit pid=1246681)[0m Fitting Client 16
[2m[36m(launch_and_fit pid=1246682)[0m Fitting Client 3
[2m[36m(launch_and_fit pid=1246683)[0m Fitting Client 15
[2m[36m(launch_and_fit pid=1246684)[0m Fitting Client 17
[2m[36m(launch_and_fit pid=1246685)[0m Fitting Client 1
[2m[36m(launch_and_fit pid=1246679)[0m Epoch 5 : loss 2.025153431541041, acc 0.1936842105263158
[2m[36m(launch_and_fit pid=1246678)[0m Epoch 5 : loss 2.046687215704667, acc 0.2231578947368421
[2m[36m(launch_and_fit pid=1246680)[0m Epoch 5 : loss 2.305235268040707, acc 0.11073684210526316
[2m[36m(launch_and_fit pid=1246684)[0m Epoch 5 : loss 2.1426177500674597, acc 0.17389473684210527
[2m[36m(launch_and_fit pid=1246682)[0m Epoch 5 : loss 2.0483171908729956, acc 0.1966315789473684
[2m[36m(launch_and_fit pid=1246681)[0m Epoch 5 : loss 2.309393558702971, acc 0.11073684210526316
[2m[36m(launch_and_fit pid=1246683)[0m Epoch 5 : loss 2.0649134766428094, acc 0.17642105263157895
[2m[36m(launch_and_fit pid=1246685)[0m Epoch 5 : loss 2.047783136869732, acc 0.19452631578947369
[2m[36m(launch_and_fit pid=1246679)[0m Epoch 10 : loss 1.942836280421207, acc 0.22610526315789473
[2m[36m(launch_and_fit pid=1246678)[0m Epoch 10 : loss 1.9586264957628752, acc 0.21473684210526317
[2m[36m(launch_and_fit pid=1246680)[0m Epoch 10 : loss 2.3065740878456515, acc 0.11663157894736842
[2m[36m(launch_and_fit pid=1246681)[0m Epoch 10 : loss 2.3125911254882814, acc 0.11410526315789474
[2m[36m(launch_and_fit pid=1246684)[0m Epoch 10 : loss 1.9891917435495476, acc 0.18947368421052632
[2m[36m(launch_and_fit pid=1246682)[0m Epoch 10 : loss 1.940908143696032, acc 0.22021052631578947
[2m[36m(launch_and_fit pid=1246683)[0m Epoch 10 : loss 1.9840780567369962, acc 0.192
[2m[36m(launch_and_fit pid=1246685)[0m Epoch 10 : loss 2.0003628901431436, acc 0.1966315789473684
Performing server side distillation training...
step 100, val_acc : 0.2
step 200, val_acc : 0.2224
E0426 12:51:59.804468969 1155705 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
Distillation training stopped at step number : 282
Fusion training loss : 0.5625303710830656, val accuracy : 0.20979290780141843
INFO flwr 2023-04-26 12:52:11,940 | server.py:116 | fit progress: (18, 2.031539577102661, {'server_test_acc': 0.2182}, 3989.1265685490216)
INFO flwr 2023-04-26 12:52:11,940 | server.py:163 | evaluate_round 18: no clients selected, cancel
DEBUG flwr 2023-04-26 12:52:11,940 | server.py:215 | fit_round 19: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:52:53,761 | server.py:229 | fit_round 19 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=1347014)[0m Fitting Client 10
[2m[36m(launch_and_fit pid=1347019)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=1347015)[0m Fitting Client 17
[2m[36m(launch_and_fit pid=1347016)[0m Fitting Client 0
[2m[36m(launch_and_fit pid=1347021)[0m Fitting Client 1
[2m[36m(launch_and_fit pid=1347020)[0m Fitting Client 11
[2m[36m(launch_and_fit pid=1347017)[0m Fitting Client 16
[2m[36m(launch_and_fit pid=1347018)[0m Fitting Client 7
[2m[36m(launch_and_fit pid=1347014)[0m Epoch 5 : loss 2.1434508498342413, acc 0.16757894736842105
[2m[36m(launch_and_fit pid=1347015)[0m Epoch 5 : loss 2.0074214489585476, acc 0.19494736842105262
[2m[36m(launch_and_fit pid=1347017)[0m Epoch 5 : loss 2.099987533569336, acc 0.1608421052631579
[2m[36m(launch_and_fit pid=1347016)[0m Epoch 5 : loss 2.1798404428582443, acc 0.1696842105263158
[2m[36m(launch_and_fit pid=1347020)[0m Epoch 5 : loss 2.309163699902986, acc 0.12042105263157894
[2m[36m(launch_and_fit pid=1347021)[0m Epoch 5 : loss 2.068175606978567, acc 0.18357894736842106
[2m[36m(launch_and_fit pid=1347018)[0m Epoch 5 : loss 1.9900333191721062, acc 0.21263157894736842
[2m[36m(launch_and_fit pid=1347019)[0m Epoch 5 : loss 2.3074396643387645, acc 0.11326315789473684
[2m[36m(launch_and_fit pid=1347014)[0m Epoch 10 : loss 1.972264319570441, acc 0.176
[2m[36m(launch_and_fit pid=1347015)[0m Epoch 10 : loss 1.9283977986385947, acc 0.224
[2m[36m(launch_and_fit pid=1347016)[0m Epoch 10 : loss 1.963403380544562, acc 0.20421052631578948
[2m[36m(launch_and_fit pid=1347017)[0m Epoch 10 : loss 1.9672582598234478, acc 0.18610526315789475
[2m[36m(launch_and_fit pid=1347020)[0m Epoch 10 : loss 2.306843945151881, acc 0.12042105263157894
[2m[36m(launch_and_fit pid=1347021)[0m Epoch 10 : loss 1.9625918976633172, acc 0.21852631578947368
[2m[36m(launch_and_fit pid=1347018)[0m Epoch 10 : loss 1.821247812371505, acc 0.2816842105263158
[2m[36m(launch_and_fit pid=1347019)[0m Epoch 10 : loss 2.306141774227745, acc 0.10568421052631578
Performing server side distillation training...
E0426 12:52:54.766967671 1340579 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
step 100, val_acc : 0.1744
step 200, val_acc : 0.1864
Distillation training stopped at step number : 251
Fusion training loss : 1.1051540415125538, val accuracy : 0.1836764940239044
INFO flwr 2023-04-26 12:55:05,732 | server.py:116 | fit progress: (19, 2.065594920730591, {'server_test_acc': 0.1855}, 4162.918938791001)
INFO flwr 2023-04-26 12:55:05,732 | server.py:163 | evaluate_round 19: no clients selected, cancel
DEBUG flwr 2023-04-26 12:55:05,733 | server.py:215 | fit_round 20: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:55:47,589 | server.py:229 | fit_round 20 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=1459218)[0m Fitting Client 2
[2m[36m(launch_and_fit pid=1459220)[0m Fitting Client 19
[2m[36m(launch_and_fit pid=1459217)[0m Fitting Client 1
[2m[36m(launch_and_fit pid=1459222)[0m Fitting Client 16
[2m[36m(launch_and_fit pid=1459221)[0m Fitting Client 10
[2m[36m(launch_and_fit pid=1459224)[0m Fitting Client 3
[2m[36m(launch_and_fit pid=1459219)[0m Fitting Client 7
[2m[36m(launch_and_fit pid=1459223)[0m Fitting Client 8
[2m[36m(launch_and_fit pid=1459220)[0m Epoch 5 : loss 1.7414210795352334, acc 0.33810526315789474
[2m[36m(launch_and_fit pid=1459218)[0m Epoch 5 : loss 1.95802579498291, acc 0.23242105263157894
[2m[36m(launch_and_fit pid=1459217)[0m Epoch 5 : loss 2.223713542335912, acc 0.1528421052631579
[2m[36m(launch_and_fit pid=1459221)[0m Epoch 5 : loss 1.9544415231002004, acc 0.21936842105263157
[2m[36m(launch_and_fit pid=1459222)[0m Epoch 5 : loss 2.071592251426295, acc 0.21221052631578946
[2m[36m(launch_and_fit pid=1459223)[0m Epoch 5 : loss 2.0633022372597143, acc 0.17810526315789474
[2m[36m(launch_and_fit pid=1459219)[0m Epoch 5 : loss 2.0645478507594057, acc 0.19705263157894737
[2m[36m(launch_and_fit pid=1459224)[0m Epoch 5 : loss 2.3161842506810237, acc 0.10736842105263159
[2m[36m(launch_and_fit pid=1459220)[0m Epoch 10 : loss 1.5654510227002596, acc 0.40042105263157896
[2m[36m(launch_and_fit pid=1459218)[0m Epoch 10 : loss 1.8219831382349918, acc 0.3065263157894737
[2m[36m(launch_and_fit pid=1459217)[0m Epoch 10 : loss 1.9387188704641243, acc 0.2471578947368421
[2m[36m(launch_and_fit pid=1459221)[0m Epoch 10 : loss 1.7710999872308029, acc 0.30105263157894735
[2m[36m(launch_and_fit pid=1459222)[0m Epoch 10 : loss 1.9766106495104339, acc 0.2033684210526316
[2m[36m(launch_and_fit pid=1459223)[0m Epoch 10 : loss 1.9844050582082648, acc 0.18147368421052631
[2m[36m(launch_and_fit pid=1459219)[0m Epoch 10 : loss 1.9589925577264082, acc 0.2025263157894737
[2m[36m(launch_and_fit pid=1459224)[0m Epoch 10 : loss 2.311809859024851, acc 0.10736842105263159
Performing server side distillation training...
E0426 12:55:50.818709940 1475317 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
step 100, val_acc : 0.1976
step 200, val_acc : 0.21
step 300, val_acc : 0.2208
Distillation training stopped at step number : 303
Fusion training loss : 1.1709255477284441, val accuracy : 0.2090864686468647
INFO flwr 2023-04-26 12:58:26,991 | server.py:116 | fit progress: (20, 2.020155277824402, {'server_test_acc': 0.2141}, 4364.177432604018)
INFO flwr 2023-04-26 12:58:26,991 | server.py:163 | evaluate_round 20: no clients selected, cancel
DEBUG flwr 2023-04-26 12:58:26,991 | server.py:215 | fit_round 21: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 12:59:08,283 | server.py:229 | fit_round 21 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=1565627)[0m Fitting Client 8
[2m[36m(launch_and_fit pid=1565630)[0m Fitting Client 15
[2m[36m(launch_and_fit pid=1565629)[0m Fitting Client 6
[2m[36m(launch_and_fit pid=1565632)[0m Fitting Client 3
[2m[36m(launch_and_fit pid=1565635)[0m Fitting Client 7
[2m[36m(launch_and_fit pid=1565634)[0m Fitting Client 12
[2m[36m(launch_and_fit pid=1565631)[0m Fitting Client 4
[2m[36m(launch_and_fit pid=1565633)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=1565630)[0m Epoch 5 : loss 2.3082871029502465, acc 0.11621052631578947
[2m[36m(launch_and_fit pid=1565627)[0m Epoch 5 : loss 2.0001084008467824, acc 0.20757894736842106
[2m[36m(launch_and_fit pid=1565629)[0m Epoch 5 : loss 2.041414336756656, acc 0.17978947368421053
[2m[36m(launch_and_fit pid=1565635)[0m Epoch 5 : loss 2.058103133352179, acc 0.18021052631578946
[2m[36m(launch_and_fit pid=1565634)[0m Epoch 5 : loss 2.0252777609574166, acc 0.21010526315789474
[2m[36m(launch_and_fit pid=1565632)[0m Epoch 5 : loss 2.3079501318680613, acc 0.10526315789473684
[2m[36m(launch_and_fit pid=1565631)[0m Epoch 5 : loss 2.314951387104235, acc 0.11410526315789474
[2m[36m(launch_and_fit pid=1565633)[0m Epoch 5 : loss 2.3012612144068667, acc 0.10905263157894737
[2m[36m(launch_and_fit pid=1565630)[0m Epoch 10 : loss 2.3440953076011257, acc 0.13347368421052633
[2m[36m(launch_and_fit pid=1565627)[0m Epoch 10 : loss 1.95237187636526, acc 0.21642105263157896
[2m[36m(launch_and_fit pid=1565629)[0m Epoch 10 : loss 1.959108727304559, acc 0.18947368421052632
[2m[36m(launch_and_fit pid=1565635)[0m Epoch 10 : loss 1.9492403046457392, acc 0.1823157894736842
[2m[36m(launch_and_fit pid=1565634)[0m Epoch 10 : loss 1.9474930624710887, acc 0.22189473684210526
[2m[36m(launch_and_fit pid=1565632)[0m Epoch 10 : loss 2.310901127062346, acc 0.10442105263157894
[2m[36m(launch_and_fit pid=1565631)[0m Epoch 10 : loss 2.307154176812423, acc 0.112
[2m[36m(launch_and_fit pid=1565633)[0m Epoch 10 : loss 2.309347543013723, acc 0.11073684210526316
Performing server side distillation training...
E0426 12:59:15.003461224 1584339 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
step 100, val_acc : 0.1896
step 200, val_acc : 0.1924
Distillation training stopped at step number : 251
Fusion training loss : 0.5599428458191247, val accuracy : 0.1865577689243028
INFO flwr 2023-04-26 13:01:21,376 | server.py:116 | fit progress: (21, 2.0560751281738283, {'server_test_acc': 0.2016}, 4538.5621859170205)
INFO flwr 2023-04-26 13:01:21,376 | server.py:163 | evaluate_round 21: no clients selected, cancel
DEBUG flwr 2023-04-26 13:01:21,376 | server.py:215 | fit_round 22: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 13:02:03,299 | server.py:229 | fit_round 22 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=1656435)[0m Fitting Client 6
[2m[36m(launch_and_fit pid=1656437)[0m Fitting Client 13
[2m[36m(launch_and_fit pid=1656434)[0m Fitting Client 17
[2m[36m(launch_and_fit pid=1656438)[0m Fitting Client 5
[2m[36m(launch_and_fit pid=1656440)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=1656436)[0m Fitting Client 3
[2m[36m(launch_and_fit pid=1656441)[0m Fitting Client 15
[2m[36m(launch_and_fit pid=1656439)[0m Fitting Client 19
[2m[36m(launch_and_fit pid=1656438)[0m Epoch 5 : loss 2.3101482299001592, acc 0.10021052631578947
[2m[36m(launch_and_fit pid=1656439)[0m Epoch 5 : loss 1.7593893866288035, acc 0.32589473684210524
[2m[36m(launch_and_fit pid=1656435)[0m Epoch 5 : loss 2.2300952433535928, acc 0.16252631578947369
[2m[36m(launch_and_fit pid=1656434)[0m Epoch 5 : loss 2.3138065988641037, acc 0.10484210526315789
[2m[36m(launch_and_fit pid=1656437)[0m Epoch 5 : loss 2.314322809319747, acc 0.09515789473684211
[2m[36m(launch_and_fit pid=1656440)[0m Epoch 5 : loss 2.1882868427477384, acc 0.16421052631578947
[2m[36m(launch_and_fit pid=1656441)[0m Epoch 5 : loss 2.181745196693822, acc 0.1688421052631579
[2m[36m(launch_and_fit pid=1656436)[0m Epoch 5 : loss 2.018076136940404, acc 0.19705263157894737
[2m[36m(launch_and_fit pid=1656438)[0m Epoch 10 : loss 2.311330507378829, acc 0.11621052631578947
[2m[36m(launch_and_fit pid=1656439)[0m Epoch 10 : loss 1.7229063676532945, acc 0.3473684210526316
[2m[36m(launch_and_fit pid=1656435)[0m Epoch 10 : loss 2.101799142134817, acc 0.1751578947368421
[2m[36m(launch_and_fit pid=1656434)[0m Epoch 10 : loss 2.3114469002171565, acc 0.11115789473684211
[2m[36m(launch_and_fit pid=1656437)[0m Epoch 10 : loss 2.3181420761911493, acc 0.08968421052631578
[2m[36m(launch_and_fit pid=1656440)[0m Epoch 10 : loss 2.0087167607357626, acc 0.19452631578947369
[2m[36m(launch_and_fit pid=1656441)[0m Epoch 10 : loss 1.9643815098812705, acc 0.18442105263157896
[2m[36m(launch_and_fit pid=1656436)[0m Epoch 10 : loss 1.9627520246003805, acc 0.19789473684210526
Performing server side distillation training...
E0426 13:02:05.006464037 1672490 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
step 100, val_acc : 0.1764
step 200, val_acc : 0.1832
E0426 13:03:56.164521765 1734883 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
Distillation training stopped at step number : 251
Fusion training loss : 0.31519467380654764, val accuracy : 0.1804127490039841
INFO flwr 2023-04-26 13:04:17,273 | server.py:116 | fit progress: (22, 2.122226558303833, {'server_test_acc': 0.1917}, 4714.459969671007)
INFO flwr 2023-04-26 13:04:17,274 | server.py:163 | evaluate_round 22: no clients selected, cancel
DEBUG flwr 2023-04-26 13:04:17,274 | server.py:215 | fit_round 23: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 13:04:59,330 | server.py:229 | fit_round 23 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=1747215)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=1747218)[0m Fitting Client 12
[2m[36m(launch_and_fit pid=1747219)[0m Fitting Client 11
[2m[36m(launch_and_fit pid=1747216)[0m Fitting Client 1
[2m[36m(launch_and_fit pid=1747214)[0m Fitting Client 3
[2m[36m(launch_and_fit pid=1747221)[0m Fitting Client 15
[2m[36m(launch_and_fit pid=1747217)[0m Fitting Client 14
[2m[36m(launch_and_fit pid=1747220)[0m Fitting Client 5
[2m[36m(launch_and_fit pid=1747214)[0m Epoch 5 : loss 2.312716350354646, acc 0.10484210526315789
[2m[36m(launch_and_fit pid=1747219)[0m Epoch 5 : loss 2.307086733366314, acc 0.11326315789473684
[2m[36m(launch_and_fit pid=1747217)[0m Epoch 5 : loss 2.0085944398578843, acc 0.20968421052631578
[2m[36m(launch_and_fit pid=1747221)[0m Epoch 5 : loss 2.087773423445852, acc 0.18147368421052631
[2m[36m(launch_and_fit pid=1747215)[0m Epoch 5 : loss 2.1219643145109477, acc 0.17936842105263157
[2m[36m(launch_and_fit pid=1747218)[0m Epoch 5 : loss 1.9967291745637592, acc 0.23031578947368422
[2m[36m(launch_and_fit pid=1747216)[0m Epoch 5 : loss 2.237516506797389, acc 0.14652631578947367
[2m[36m(launch_and_fit pid=1747220)[0m Epoch 5 : loss 2.0281504287719727, acc 0.2063157894736842
[2m[36m(launch_and_fit pid=1747214)[0m Epoch 10 : loss 2.313899957757247, acc 0.10105263157894737
[2m[36m(launch_and_fit pid=1747219)[0m Epoch 10 : loss 2.307590646041067, acc 0.11157894736842106
[2m[36m(launch_and_fit pid=1747217)[0m Epoch 10 : loss 1.936161316721063, acc 0.21052631578947367
[2m[36m(launch_and_fit pid=1747221)[0m Epoch 10 : loss 1.9237483488384046, acc 0.20884210526315788
[2m[36m(launch_and_fit pid=1747215)[0m Epoch 10 : loss 1.9825888202064916, acc 0.1848421052631579
[2m[36m(launch_and_fit pid=1747218)[0m Epoch 10 : loss 1.8860170063219572, acc 0.2551578947368421
[2m[36m(launch_and_fit pid=1747216)[0m Epoch 10 : loss 2.0404189694053247, acc 0.17936842105263157
[2m[36m(launch_and_fit pid=1747220)[0m Epoch 10 : loss 1.8820392853586296, acc 0.2631578947368421
Performing server side distillation training...
step 100, val_acc : 0.23
step 200, val_acc : 0.2304
step 300, val_acc : 0.2448
E0426 13:08:01.702511336 1735837 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
step 400, val_acc : 0.2468
Distillation training stopped at step number : 488
Fusion training loss : 0.21367612193704996, val accuracy : 0.23544836065573768
INFO flwr 2023-04-26 13:09:18,011 | server.py:116 | fit progress: (23, 1.9861175479888915, {'server_test_acc': 0.2534}, 5015.197175673005)
INFO flwr 2023-04-26 13:09:18,011 | server.py:163 | evaluate_round 23: no clients selected, cancel
DEBUG flwr 2023-04-26 13:09:18,011 | server.py:215 | fit_round 24: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 13:09:59,587 | server.py:229 | fit_round 24 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=1928683)[0m Fitting Client 3
[2m[36m(launch_and_fit pid=1928727)[0m Fitting Client 14
[2m[36m(launch_and_fit pid=1928726)[0m Fitting Client 6
[2m[36m(launch_and_fit pid=1928725)[0m Fitting Client 7
[2m[36m(launch_and_fit pid=1928732)[0m Fitting Client 15
[2m[36m(launch_and_fit pid=1928731)[0m Fitting Client 16
[2m[36m(launch_and_fit pid=1928730)[0m Fitting Client 2
[2m[36m(launch_and_fit pid=1928729)[0m Fitting Client 17
[2m[36m(launch_and_fit pid=1928726)[0m Epoch 5 : loss 2.017105359930741, acc 0.21221052631578946
[2m[36m(launch_and_fit pid=1928727)[0m Epoch 5 : loss 2.0594175937050267, acc 0.19621052631578947
[2m[36m(launch_and_fit pid=1928725)[0m Epoch 5 : loss 1.9963986093621504, acc 0.18863157894736843
[2m[36m(launch_and_fit pid=1928730)[0m Epoch 5 : loss 2.059479652003238, acc 0.19031578947368422
[2m[36m(launch_and_fit pid=1928731)[0m Epoch 5 : loss 1.9994578022203948, acc 0.21136842105263157
[2m[36m(launch_and_fit pid=1928729)[0m Epoch 5 : loss 2.313614343743575, acc 0.10063157894736842
[2m[36m(launch_and_fit pid=1928683)[0m Epoch 5 : loss 2.318144435681795, acc 0.09515789473684211
[2m[36m(launch_and_fit pid=1928732)[0m Epoch 5 : loss 2.0373915935315585, acc 0.21221052631578946
[2m[36m(launch_and_fit pid=1928726)[0m Epoch 10 : loss 1.9278542645103054, acc 0.21978947368421053
[2m[36m(launch_and_fit pid=1928727)[0m Epoch 10 : loss 1.9307723340486225, acc 0.21347368421052632
[2m[36m(launch_and_fit pid=1928725)[0m Epoch 10 : loss 1.9316042343942743, acc 0.21263157894736842
[2m[36m(launch_and_fit pid=1928730)[0m Epoch 10 : loss 1.8355534073679072, acc 0.26063157894736844
[2m[36m(launch_and_fit pid=1928729)[0m Epoch 10 : loss 2.3107526670757093, acc 0.112
[2m[36m(launch_and_fit pid=1928731)[0m Epoch 10 : loss 1.8978498322336297, acc 0.23494736842105263
[2m[36m(launch_and_fit pid=1928683)[0m Epoch 10 : loss 2.3145548537404914, acc 0.09094736842105264
[2m[36m(launch_and_fit pid=1928732)[0m Epoch 10 : loss 1.84282670553107, acc 0.28
Performing server side distillation training...
E0426 13:10:00.894545855 1945565 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
step 100, val_acc : 0.24
step 200, val_acc : 0.2352
E0426 13:11:46.741678355 2005160 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
Distillation training stopped at step number : 251
Fusion training loss : 0.2122477760827874, val accuracy : 0.23395697211155378
INFO flwr 2023-04-26 13:12:14,474 | server.py:116 | fit progress: (24, 1.9634997360229491, {'server_test_acc': 0.2321}, 5191.661085861007)
INFO flwr 2023-04-26 13:12:14,475 | server.py:163 | evaluate_round 24: no clients selected, cancel
DEBUG flwr 2023-04-26 13:12:14,475 | server.py:215 | fit_round 25: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 13:12:56,364 | server.py:229 | fit_round 25 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=2021153)[0m Fitting Client 12
[2m[36m(launch_and_fit pid=2021156)[0m Fitting Client 19
[2m[36m(launch_and_fit pid=2021151)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=2021149)[0m Fitting Client 14
[2m[36m(launch_and_fit pid=2021155)[0m Fitting Client 13
[2m[36m(launch_and_fit pid=2021150)[0m Fitting Client 7
[2m[36m(launch_and_fit pid=2021154)[0m Fitting Client 2
[2m[36m(launch_and_fit pid=2021152)[0m Fitting Client 8
[2m[36m(launch_and_fit pid=2021154)[0m Epoch 5 : loss 1.9860451852898848, acc 0.20042105263157894
[2m[36m(launch_and_fit pid=2021153)[0m Epoch 5 : loss 2.30441445039448, acc 0.11031578947368421
[2m[36m(launch_and_fit pid=2021151)[0m Epoch 5 : loss 2.2033057351363334, acc 0.15410526315789475
[2m[36m(launch_and_fit pid=2021155)[0m Epoch 5 : loss 2.3181888018156354, acc 0.09347368421052632
[2m[36m(launch_and_fit pid=2021152)[0m Epoch 5 : loss 2.2592337839226975, acc 0.13178947368421054
[2m[36m(launch_and_fit pid=2021150)[0m Epoch 5 : loss 2.0161220944053246, acc 0.19494736842105262
[2m[36m(launch_and_fit pid=2021156)[0m Epoch 5 : loss 1.7965518867091128, acc 0.29557894736842105
[2m[36m(launch_and_fit pid=2021149)[0m Epoch 5 : loss 2.159328508477462, acc 0.17810526315789474
[2m[36m(launch_and_fit pid=2021154)[0m Epoch 10 : loss 1.8663490801359477, acc 0.2522105263157895
[2m[36m(launch_and_fit pid=2021153)[0m Epoch 10 : loss 2.3034460232383327, acc 0.10905263157894737
[2m[36m(launch_and_fit pid=2021151)[0m Epoch 10 : loss 1.9901208576403167, acc 0.20294736842105263
[2m[36m(launch_and_fit pid=2021155)[0m Epoch 10 : loss 2.313877780311986, acc 0.09263157894736843
[2m[36m(launch_and_fit pid=2021152)[0m Epoch 10 : loss 2.0120627602025083, acc 0.208
[2m[36m(launch_and_fit pid=2021156)[0m Epoch 10 : loss 1.73269323971397, acc 0.3368421052631579
[2m[36m(launch_and_fit pid=2021149)[0m Epoch 10 : loss 1.9804560040925678, acc 0.1911578947368421
[2m[36m(launch_and_fit pid=2021150)[0m Epoch 10 : loss 1.8976718741969059, acc 0.2581052631578947
Performing server side distillation training...
step 100, val_acc : 0.2
step 200, val_acc : 0.1908
Distillation training stopped at step number : 251
Fusion training loss : 0.6599432089889192, val accuracy : 0.20263107569721114
INFO flwr 2023-04-26 13:15:11,170 | server.py:116 | fit progress: (25, 2.117335219192505, {'server_test_acc': 0.2116}, 5368.356703888014)
INFO flwr 2023-04-26 13:15:11,170 | server.py:163 | evaluate_round 25: no clients selected, cancel
DEBUG flwr 2023-04-26 13:15:11,170 | server.py:215 | fit_round 26: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 13:15:53,400 | server.py:229 | fit_round 26 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=2111968)[0m Fitting Client 14
[2m[36m(launch_and_fit pid=2111964)[0m Fitting Client 0
[2m[36m(launch_and_fit pid=2111962)[0m Fitting Client 1
[2m[36m(launch_and_fit pid=2111966)[0m Fitting Client 19
[2m[36m(launch_and_fit pid=2111967)[0m Fitting Client 12
[2m[36m(launch_and_fit pid=2111959)[0m Fitting Client 3
[2m[36m(launch_and_fit pid=2111965)[0m Fitting Client 2
[2m[36m(launch_and_fit pid=2111963)[0m Fitting Client 17
[2m[36m(launch_and_fit pid=2111968)[0m Epoch 5 : loss 2.027061325474789, acc 0.192
[2m[36m(launch_and_fit pid=2111963)[0m Epoch 5 : loss 2.0885410373085422, acc 0.2033684210526316
[2m[36m(launch_and_fit pid=2111964)[0m Epoch 5 : loss 2.1198742209986636, acc 0.1734736842105263
[2m[36m(launch_and_fit pid=2111967)[0m Epoch 5 : loss 2.303601917467619, acc 0.11831578947368421
[2m[36m(launch_and_fit pid=2111966)[0m Epoch 5 : loss 1.7699951444927016, acc 0.33010526315789473
[2m[36m(launch_and_fit pid=2111962)[0m Epoch 5 : loss 2.310895262065687, acc 0.11368421052631579
[2m[36m(launch_and_fit pid=2111959)[0m Epoch 5 : loss 2.075807647705078, acc 0.17978947368421053
[2m[36m(launch_and_fit pid=2111965)[0m Epoch 5 : loss 2.105667825799239, acc 0.1608421052631579
[2m[36m(launch_and_fit pid=2111968)[0m Epoch 10 : loss 1.9548020597759046, acc 0.22063157894736843
[2m[36m(launch_and_fit pid=2111963)[0m Epoch 10 : loss 1.900850267109118, acc 0.2576842105263158
[2m[36m(launch_and_fit pid=2111964)[0m Epoch 10 : loss 1.9783740563643606, acc 0.1751578947368421
[2m[36m(launch_and_fit pid=2111967)[0m Epoch 10 : loss 2.30825632838199, acc 0.10905263157894737
[2m[36m(launch_and_fit pid=2111962)[0m Epoch 10 : loss 2.3172485777202407, acc 0.10863157894736843
[2m[36m(launch_and_fit pid=2111966)[0m Epoch 10 : loss 1.6358135231419613, acc 0.3814736842105263
[2m[36m(launch_and_fit pid=2111959)[0m Epoch 10 : loss 1.9529950416966488, acc 0.2151578947368421
[2m[36m(launch_and_fit pid=2111965)[0m Epoch 10 : loss 1.9355099029541016, acc 0.20589473684210527
Performing server side distillation training...
E0426 13:15:54.690430525 2127193 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
step 100, val_acc : 0.1956
step 200, val_acc : 0.2116
Distillation training stopped at step number : 277
Fusion training loss : 0.9408590214239562, val accuracy : 0.2047927797833935
INFO flwr 2023-04-26 13:18:22,773 | server.py:116 | fit progress: (26, 2.089070014190674, {'server_test_acc': 0.2078}, 5559.959934643994)
INFO flwr 2023-04-26 13:18:22,774 | server.py:163 | evaluate_round 26: no clients selected, cancel
DEBUG flwr 2023-04-26 13:18:22,774 | server.py:215 | fit_round 27: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 13:19:04,672 | server.py:229 | fit_round 27 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=2210568)[0m Fitting Client 15
[2m[36m(launch_and_fit pid=2210569)[0m Fitting Client 13
[2m[36m(launch_and_fit pid=2210570)[0m Fitting Client 5
[2m[36m(launch_and_fit pid=2210573)[0m Fitting Client 0
[2m[36m(launch_and_fit pid=2210571)[0m Fitting Client 17
[2m[36m(launch_and_fit pid=2210575)[0m Fitting Client 16
[2m[36m(launch_and_fit pid=2210572)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=2210574)[0m Fitting Client 6
[2m[36m(launch_and_fit pid=2210575)[0m Epoch 5 : loss 2.0653468154104133, acc 0.17852631578947367
[2m[36m(launch_and_fit pid=2210568)[0m Epoch 5 : loss 2.0732558657997533, acc 0.19747368421052633
[2m[36m(launch_and_fit pid=2210574)[0m Epoch 5 : loss 2.2017536982486123, acc 0.15157894736842106
[2m[36m(launch_and_fit pid=2210569)[0m Epoch 5 : loss 2.3126448725650186, acc 0.10736842105263159
[2m[36m(launch_and_fit pid=2210572)[0m Epoch 5 : loss 2.3056254208213405, acc 0.11115789473684211
[2m[36m(launch_and_fit pid=2210570)[0m Epoch 5 : loss 2.0479179085179378, acc 0.18526315789473685
[2m[36m(launch_and_fit pid=2210573)[0m Epoch 5 : loss 2.027712219238281, acc 0.1743157894736842
[2m[36m(launch_and_fit pid=2210571)[0m Epoch 5 : loss 2.300618582474558, acc 0.11747368421052631
[2m[36m(launch_and_fit pid=2210575)[0m Epoch 10 : loss 1.8675670611732884, acc 0.256
[2m[36m(launch_and_fit pid=2210568)[0m Epoch 10 : loss 1.8980477849056847, acc 0.24
[2m[36m(launch_and_fit pid=2210574)[0m Epoch 10 : loss 1.9969137167679636, acc 0.17473684210526316
[2m[36m(launch_and_fit pid=2210569)[0m Epoch 10 : loss 2.256954226042095, acc 0.14989473684210528
[2m[36m(launch_and_fit pid=2210572)[0m Epoch 10 : loss 2.3092057800292967, acc 0.11578947368421053
[2m[36m(launch_and_fit pid=2210570)[0m Epoch 10 : loss 2.012609722739772, acc 0.18778947368421053
[2m[36m(launch_and_fit pid=2210573)[0m Epoch 10 : loss 1.941838374087685, acc 0.20378947368421052
[2m[36m(launch_and_fit pid=2210571)[0m Epoch 10 : loss 2.086861730475175, acc 0.18947368421052632
Performing server side distillation training...
E0426 13:19:07.897629874 2226389 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
step 100, val_acc : 0.2244
step 200, val_acc : 0.2268
step 300, val_acc : 0.2284
step 400, val_acc : 0.2212
Distillation training stopped at step number : 428
Fusion training loss : 0.39200898712483523, val accuracy : 0.21995420560747667
INFO flwr 2023-04-26 13:22:55,082 | server.py:116 | fit progress: (27, 2.009457444381714, {'server_test_acc': 0.2159}, 5832.269017087005)
INFO flwr 2023-04-26 13:22:55,083 | server.py:163 | evaluate_round 27: no clients selected, cancel
DEBUG flwr 2023-04-26 13:22:55,083 | server.py:215 | fit_round 28: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 13:23:37,555 | server.py:229 | fit_round 28 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=2396011)[0m Fitting Client 5
[2m[36m(launch_and_fit pid=2396012)[0m Fitting Client 12
[2m[36m(launch_and_fit pid=2396014)[0m Fitting Client 0
[2m[36m(launch_and_fit pid=2396015)[0m Fitting Client 14
[2m[36m(launch_and_fit pid=2396019)[0m Fitting Client 13
[2m[36m(launch_and_fit pid=2396013)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=2396018)[0m Fitting Client 8
[2m[36m(launch_and_fit pid=2396017)[0m Fitting Client 16
[2m[36m(launch_and_fit pid=2396011)[0m Epoch 5 : loss 2.0026706803974355, acc 0.19536842105263158
[2m[36m(launch_and_fit pid=2396014)[0m Epoch 5 : loss 1.9289278203060753, acc 0.2353684210526316
[2m[36m(launch_and_fit pid=2396012)[0m Epoch 5 : loss 1.9433947336297286, acc 0.2501052631578947
[2m[36m(launch_and_fit pid=2396013)[0m Epoch 5 : loss 2.197821752447831, acc 0.15957894736842104
[2m[36m(launch_and_fit pid=2396019)[0m Epoch 5 : loss 2.136320332175807, acc 0.17852631578947367
[2m[36m(launch_and_fit pid=2396018)[0m Epoch 5 : loss 2.041514180233604, acc 0.2168421052631579
[2m[36m(launch_and_fit pid=2396017)[0m Epoch 5 : loss 2.3116858046682256, acc 0.11368421052631579
[2m[36m(launch_and_fit pid=2396015)[0m Epoch 5 : loss 1.9917451609561319, acc 0.19957894736842105
[2m[36m(launch_and_fit pid=2396011)[0m Epoch 10 : loss 1.9033578804417661, acc 0.22989473684210526
[2m[36m(launch_and_fit pid=2396014)[0m Epoch 10 : loss 1.827609569348787, acc 0.2783157894736842
[2m[36m(launch_and_fit pid=2396012)[0m Epoch 10 : loss 1.8211346046046206, acc 0.29557894736842105
[2m[36m(launch_and_fit pid=2396013)[0m Epoch 10 : loss 1.9480542273270456, acc 0.19747368421052633
[2m[36m(launch_and_fit pid=2396019)[0m Epoch 10 : loss 1.938244997928017, acc 0.21894736842105264
[2m[36m(launch_and_fit pid=2396018)[0m Epoch 10 : loss 1.969759347212942, acc 0.2256842105263158
[2m[36m(launch_and_fit pid=2396017)[0m Epoch 10 : loss 2.3157539986058286, acc 0.10442105263157894
[2m[36m(launch_and_fit pid=2396015)[0m Epoch 10 : loss 1.9377776846634713, acc 0.216
Performing server side distillation training...
step 100, val_acc : 0.1192
E0426 13:24:36.507506649 2461575 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
step 200, val_acc : 0.1268
step 300, val_acc : 0.1276
step 400, val_acc : 0.1228
Distillation training stopped at step number : 482
Fusion training loss : 5.777722632736586, val accuracy : 0.1206265560165975
INFO flwr 2023-04-26 13:27:57,411 | server.py:116 | fit progress: (28, 2.677782340621948, {'server_test_acc': 0.1249}, 6134.598096591013)
INFO flwr 2023-04-26 13:27:57,412 | server.py:163 | evaluate_round 28: no clients selected, cancel
DEBUG flwr 2023-04-26 13:27:57,412 | server.py:215 | fit_round 29: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 13:28:39,586 | server.py:229 | fit_round 29 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=2573332)[0m Fitting Client 3
[2m[36m(launch_and_fit pid=2573336)[0m Fitting Client 19
[2m[36m(launch_and_fit pid=2573329)[0m Fitting Client 14
[2m[36m(launch_and_fit pid=2573335)[0m Fitting Client 16
[2m[36m(launch_and_fit pid=2573334)[0m Fitting Client 15
[2m[36m(launch_and_fit pid=2573333)[0m Fitting Client 4
[2m[36m(launch_and_fit pid=2573330)[0m Fitting Client 9
[2m[36m(launch_and_fit pid=2573331)[0m Fitting Client 13
[2m[36m(launch_and_fit pid=2573330)[0m Epoch 5 : loss 1.9687751308240389, acc 0.19831578947368422
[2m[36m(launch_and_fit pid=2573336)[0m Epoch 5 : loss 1.7804077698557002, acc 0.2808421052631579
[2m[36m(launch_and_fit pid=2573334)[0m Epoch 5 : loss 1.9357037064401728, acc 0.21936842105263157
[2m[36m(launch_and_fit pid=2573335)[0m Epoch 5 : loss 1.9783779521741365, acc 0.20421052631578948
[2m[36m(launch_and_fit pid=2573329)[0m Epoch 5 : loss 2.0277868664390164, acc 0.176
[2m[36m(launch_and_fit pid=2573333)[0m Epoch 5 : loss 1.9807511175055252, acc 0.19621052631578947
[2m[36m(launch_and_fit pid=2573331)[0m Epoch 5 : loss 1.9793237344842207, acc 0.2063157894736842
[2m[36m(launch_and_fit pid=2573332)[0m Epoch 5 : loss 1.9758759107087789, acc 0.18147368421052631
[2m[36m(launch_and_fit pid=2573330)[0m Epoch 10 : loss 1.9721493610582854, acc 0.21347368421052632
[2m[36m(launch_and_fit pid=2573336)[0m Epoch 10 : loss 1.671648846274928, acc 0.3002105263157895
[2m[36m(launch_and_fit pid=2573334)[0m Epoch 10 : loss 1.8758865324321545, acc 0.22189473684210526
[2m[36m(launch_and_fit pid=2573335)[0m Epoch 10 : loss 1.908493443137721, acc 0.24294736842105263
[2m[36m(launch_and_fit pid=2573329)[0m Epoch 10 : loss 1.9665387565211245, acc 0.19452631578947369
[2m[36m(launch_and_fit pid=2573333)[0m Epoch 10 : loss 1.9375826371845446, acc 0.22231578947368422
[2m[36m(launch_and_fit pid=2573331)[0m Epoch 10 : loss 1.95083961406507, acc 0.22063157894736843
[2m[36m(launch_and_fit pid=2573332)[0m Epoch 10 : loss 1.910037607694927, acc 0.2054736842105263
Performing server side distillation training...
E0426 13:28:42.335545037 2590377 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
step 100, val_acc : 0.0924
step 200, val_acc : 0.0992
step 300, val_acc : 0.1136
step 400, val_acc : 0.1204
step 500, val_acc : 0.1272
Distillation training stopped at step number : 500
Fusion training loss : 11.113662444591522, val accuracy : 0.10855360000000001
INFO flwr 2023-04-26 13:33:09,387 | server.py:116 | fit progress: (29, 2.567221348571777, {'server_test_acc': 0.1377}, 6446.574028580013)
INFO flwr 2023-04-26 13:33:09,388 | server.py:163 | evaluate_round 29: no clients selected, cancel
DEBUG flwr 2023-04-26 13:33:09,388 | server.py:215 | fit_round 30: strategy sampled 8 clients (out of 20)
DEBUG flwr 2023-04-26 13:33:51,211 | server.py:229 | fit_round 30 received 8 results and 0 failures
[2m[36m(launch_and_fit pid=2739469)[0m Fitting Client 18
[2m[36m(launch_and_fit pid=2739470)[0m Fitting Client 1
[2m[36m(launch_and_fit pid=2739472)[0m Fitting Client 19
[2m[36m(launch_and_fit pid=2739475)[0m Fitting Client 0
[2m[36m(launch_and_fit pid=2739474)[0m Fitting Client 17
[2m[36m(launch_and_fit pid=2739471)[0m Fitting Client 10
[2m[36m(launch_and_fit pid=2739473)[0m Fitting Client 14
[2m[36m(launch_and_fit pid=2739476)[0m Fitting Client 9
[2m[36m(launch_and_fit pid=2739470)[0m Epoch 5 : loss 2.312467159873561, acc 0.10526315789473684
[2m[36m(launch_and_fit pid=2739469)[0m Epoch 5 : loss 2.308545090524774, acc 0.11536842105263158
[2m[36m(launch_and_fit pid=2739471)[0m Epoch 5 : loss 1.9686265339098479, acc 0.20294736842105263
[2m[36m(launch_and_fit pid=2739472)[0m Epoch 5 : loss 2.091874786376953, acc 0.1705263157894737
[2m[36m(launch_and_fit pid=2739473)[0m Epoch 5 : loss 2.3104126747532896, acc 0.10484210526315789
[2m[36m(launch_and_fit pid=2739475)[0m Epoch 5 : loss 2.315704415572317, acc 0.07915789473684211
[2m[36m(launch_and_fit pid=2739474)[0m Epoch 5 : loss 1.967823630885074, acc 0.1966315789473684
[2m[36m(launch_and_fit pid=2739476)[0m Epoch 5 : loss 1.9976861427708676, acc 0.17726315789473684
[2m[36m(launch_and_fit pid=2739470)[0m Epoch 10 : loss 2.3173949336001747, acc 0.11789473684210526
[2m[36m(launch_and_fit pid=2739469)[0m Epoch 10 : loss 2.3095404711271588, acc 0.09978947368421053
[2m[36m(launch_and_fit pid=2739471)[0m Epoch 10 : loss 1.9402726436414217, acc 0.22905263157894737
[2m[36m(launch_and_fit pid=2739472)[0m Epoch 10 : loss 2.0941438518323396, acc 0.16673684210526316
[2m[36m(launch_and_fit pid=2739475)[0m Epoch 10 : loss 2.313239422045256, acc 0.10231578947368421
[2m[36m(launch_and_fit pid=2739473)[0m Epoch 10 : loss 2.3138654407701993, acc 0.09642105263157895
[2m[36m(launch_and_fit pid=2739474)[0m Epoch 10 : loss 1.9321523774799547, acc 0.19747368421052633
[2m[36m(launch_and_fit pid=2739476)[0m Epoch 10 : loss 1.9069331628899826, acc 0.22063157894736843
Performing server side distillation training...
E0426 13:33:55.910598965 2754796 chttp2_transport.cc:1079]             ipv4:145.136.62.9:61856: Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings". Current keepalive time (before throttling): ∞
step 100, val_acc : 0.104
step 200, val_acc : 0.1056
Distillation training stopped at step number : 251
Fusion training loss : 3.828655825193185, val accuracy : 0.1042964143426295
INFO flwr 2023-04-26 13:36:08,173 | server.py:116 | fit progress: (30, 2.3650878536224367, {'server_test_acc': 0.1007}, 6625.359379021014)
INFO flwr 2023-04-26 13:36:08,173 | server.py:163 | evaluate_round 30: no clients selected, cancel
INFO flwr 2023-04-26 13:36:08,173 | server.py:144 | FL finished in 6625.359680801019
INFO flwr 2023-04-26 13:36:08,175 | app.py:202 | app_fit: losses_distributed []
INFO flwr 2023-04-26 13:36:08,175 | app.py:203 | app_fit: metrics_distributed {}
INFO flwr 2023-04-26 13:36:08,175 | app.py:204 | app_fit: losses_centralized [(0, 2.2996636138916013), (1, 2.0193208530426023), (2, 2.017958446884155), (3, 2.0921402797698976), (4, 2.0080297174453734), (5, 1.9706926818847657), (6, 2.0013978366851806), (7, 1.9411804056167603), (8, 1.9844856525421142), (9, 2.101990392112732), (10, 2.0508681465148926), (11, 1.9629183238983154), (12, 2.035896958351135), (13, 2.0475500299453735), (14, 2.015881406402588), (15, 2.0029696313858034), (16, 2.274468712234497), (17, 2.115663186645508), (18, 2.031539577102661), (19, 2.065594920730591), (20, 2.020155277824402), (21, 2.0560751281738283), (22, 2.122226558303833), (23, 1.9861175479888915), (24, 1.9634997360229491), (25, 2.117335219192505), (26, 2.089070014190674), (27, 2.009457444381714), (28, 2.677782340621948), (29, 2.567221348571777), (30, 2.3650878536224367)]
INFO flwr 2023-04-26 13:36:08,175 | app.py:205 | app_fit: metrics_centralized {'server_test_acc': [(0, 0.1162), (1, 0.2062), (2, 0.2447), (3, 0.1997), (4, 0.2273), (5, 0.2599), (6, 0.2301), (7, 0.2445), (8, 0.2013), (9, 0.1946), (10, 0.2107), (11, 0.2089), (12, 0.2169), (13, 0.2103), (14, 0.2194), (15, 0.2322), (16, 0.1701), (17, 0.1817), (18, 0.2182), (19, 0.1855), (20, 0.2141), (21, 0.2016), (22, 0.1917), (23, 0.2534), (24, 0.2321), (25, 0.2116), (26, 0.2078), (27, 0.2159), (28, 0.1249), (29, 0.1377), (30, 0.1007)]}

JOB STATISTICS
==============
Job ID: 2659640
Cluster: snellius
User/Group: sunnys/sunnys
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 04:25:43
CPU Efficiency: 13.27% of 1-09:21:54 core-walltime
Job Wall-clock time: 01:51:13
Memory Utilized: 35.95 GB
Memory Efficiency: 0.00% of 0.00 MB
